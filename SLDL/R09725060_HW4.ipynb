{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 統計學習與深度學習\n",
    "#### 學號：R09725060 姓名：黃瀚陞\n",
    "\n",
    "### Homework 4\n",
    "\n",
    "請將IPYNB檔與IPYNB Export之HTML檔上傳至COOL作業區。回答作業時建議使用 \"三明治\" 答題法。也就是說，先說明要做什麼，然後列出程式碼與結果，最後說明這些結果的意義。作業自己做。嚴禁抄襲。不接受紙本繳交，不接受遲交。請以英文或中文作答。\n",
    "\n",
    "#### Multilayer Perceptrons for Regression\n",
    "本次作業的主角是 Multilayer perceptrons (MLP)。我們將以MLP建構迴歸模型，探討各項相關議題。\n",
    "\n",
    "\n",
    "#### Dataset: Million Songs Dataset\n",
    "本次作業將使用\"Million Songs Dataset\"作為訓練與測試資料。請使用`pickle.load()`載入*msd_full.pickle*。這個資料集已經切割好了訓練與測試資料，並存放在一個Dictionary的結構。這個Dictionary有四個元素，x_train, y_train, x_test, y_test，分別對應到訓練特徵、訓練標記(Label)、測試特徵、測試標記。 標記變數 (label variable; i.e., $y$) 是歌曲發行年度。特徵為歌曲的聲音特性。迴歸任務為預測歌曲年分。\n",
    "\n",
    "#### Prediction Performance and Loss Function\n",
    "模型訓練應主要使用Sum of Squared Error (SSE)建構Loss Function，另外我們也會練習使用其他種類的Loss Function。為了讓圖表易於理解，不論Loss Function為何，報告預測能力應使用Root Mean Squared Error (RMSE)。使用SSE或RMSE建構Loss Function在本質上沒有差別。但SSE計算成本稍低，而RMSE較有直觀意義。\n",
    "\n",
    "\n",
    "#### Subtraining, Validation, and Test Datasets\n",
    "*msd_full.pickle* 檔案中的訓練資料已經隨機排序過。你應該使用訓練資料最後10%的資料做為Validation Set。其餘的前90%做為Subtraining Set。使用Subtraining Set來訓練資料，並以Validation Set作為參數調教與Early Stopping的依據。Test RMSE應使用測試資料計算得之。\n",
    "\n",
    "所有特徵應該標準化(均數為零，變異數為一)。標準化應該以訓練資料(注意不是Test Set or Subtraining Set)的統計量為之。標記變數(i.e., $y$)應將均數平移至0 (依照訓練資料的統計量)。標記變數的變異數不要調整。\n",
    "\n",
    "\n",
    "#### Minibatch, Epoch, and Early Stopping\n",
    "如果沒有特別說明，模型訓練時應以大小為1,000個資料點的Minibatch為之。模型使用一個Minibatch的資料更新參數之後稱為經歷了一個Batch。當所有Subtraining資料已經用來更新過模型參數，稱為經過了一個Epoch。\n",
    "\n",
    "模型訓練應使用Early Stopping決定最佳的模型。模型訓練時每100個Batch計算一次Training and Validation RMSE。如果Validation為歷史最低，則記下當下的模型參數與當時已進行的Batch數量，稱為best_step_count。如由best_step_count起算已經經過了5,000個Batch而沒有更好的Validation RMSE，則停止模型訓練，並以best_step_count時的模型參數做為最後的模型訓練結果。如果模型訓練最多執行100個epoch。如果模型已經執行了100個epoch而沒有Early Stop，則應使用歷史最佳的Validation RMSE所對應到的模型參數計算Test RMSE。\n",
    "\n",
    "\n",
    "#### Implementation Restriction\n",
    "使用Pytorch建構MLP模型。Ordinary Least Square (OLS)模型訓練沒有限制使用何種套件。\n",
    "\n",
    "#### 資料載入\n",
    "使用下面的程式碼載入資料:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, Xnp, Ynp):\n",
    "        'Initialization, passing Xnp and Ynp'\n",
    "        self.labels = Ynp\n",
    "        self.nobs = Xnp.shape[0]        \n",
    "        self.Xnp = Xnp\n",
    "        self.Ynp = Ynp\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.nobs\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'        \n",
    "        X = self.Xnp[index]\n",
    "        y = self.Ynp[index]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape =  (463715, 90)\n",
      "X_subtrain shape =  (417344, 90)\n",
      "X_valid shape =  (46371, 90)\n",
      "Y_subtrain shape =  (417344,)\n",
      "Y_valid shape =  (46371,)\n",
      "X_test shape =  (51630, 90)\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Load data\n",
    "with open('data/msd_full.pickle', 'rb') as fh1:\n",
    "    msd_data = pickle.load(fh1)\n",
    "\n",
    "doscaling = 1\n",
    "if (doscaling == 1):\n",
    "    xscaler = preprocessing.StandardScaler().fit(msd_data['X_train'])\n",
    "    # standardize feature values\n",
    "    X_train = xscaler.transform(msd_data['X_train'])\n",
    "    X_test = xscaler.transform(msd_data['X_test'])\n",
    "else:\n",
    "    X_train = msd_data['X_train']\n",
    "    X_test = msd_data['X_test']\n",
    "\n",
    "Y_train = msd_data['Y_train']\n",
    "Y_test = msd_data['Y_test'].astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "y_mean = Y_train.mean()\n",
    "Y_train_keep = Y_train.copy()\n",
    "Y_test_keep = Y_test.copy()\n",
    "Y_train = Y_train - y_mean\n",
    "Y_test = Y_test - y_mean\n",
    "\n",
    "\n",
    "# validation is the last 10% of training, subtraining is the first 90% of training\n",
    "nvalid = int(X_train.shape[0] * 0.1)\n",
    "nsubtrain = X_train.shape[0] - nvalid\n",
    "\n",
    "X_subtrain = X_train[0:nsubtrain, :].astype('float32')\n",
    "X_valid = X_train[nsubtrain:, :].astype('float32')\n",
    "Y_subtrain = Y_train[0:nsubtrain].astype('float32')\n",
    "Y_valid = Y_train[nsubtrain:].astype('float32')\n",
    "\n",
    "Y_subtrain_keep = Y_train_keep[0:nsubtrain].astype('float32')\n",
    "Y_valid_keep = Y_train_keep[nsubtrain:].astype('float32')\n",
    "\n",
    "print(\"X_train shape = \", X_train.shape)\n",
    "print(\"X_subtrain shape = \", X_subtrain.shape)\n",
    "print(\"X_valid shape = \", X_valid.shape)\n",
    "print(\"Y_subtrain shape = \", Y_subtrain.shape)\n",
    "print(\"Y_valid shape = \", Y_valid.shape)\n",
    "print(\"X_test shape = \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回答下面問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 (5%)\n",
    "使用Training資料訓練一個Ordinary Least Square模型，並進行預測。列出此模型的RMSE與前五個特徵的參數。OLS模型應包含常數項，且不應有任何Regularization。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 9.510160684544399\n",
      "Parameters: [ 5.30975265 -2.88088114 -1.53234348  0.05737583 -0.33952889]\n"
     ]
    }
   ],
   "source": [
    "linear_reg=LinearRegression().fit(X_train,Y_train)\n",
    "y_pred=linear_reg.predict(X_test)\n",
    "mse=mean_squared_error(Y_test,y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"RMSE:\",rmse)\n",
    "print(\"Parameters:\",linear_reg.coef_[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1 解釋：  \n",
    "使用sklearn的Linear Regression來建模並預測，得RMSE約為9.51，前五項特徵的參數如上輸出(Parameters)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2 MLP with Four Hidden Layers (15%)\n",
    "建構一個有四層Hidden Layer的MLP。此模型由輸入層開始，90個Input Features通過線性層轉換為H個Hidden Nodes，並通過ReLu Activation Function，此為第一層Hidden Layer。\n",
    "接著通過下一個線性層與ReLu Activation Function，此為第二層。接著下一個線性層與ReLu Activation Function，此為第三層。\n",
    "然後下一個線性層與ReLu Activation Function，此為第四層。最後通過一個線性層輸出。\n",
    "所有Hidden Layer的寬度都為H。\n",
    "\n",
    "令H= 45, 使用Stochastic Gradient Descent更新參數，設Learning Rate = 0.00001，無Weight Decay與Momentum。畫出模型訓練過程中的Training與Validation RMSE，列出Test RMSE。 並討論訓練過程中Training與Validation RMSE的圖形意義。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtrainset=Dataset(X_subtrain,Y_subtrain)    \n",
    "validset=Dataset(X_valid,Y_valid)\n",
    "testset=Dataset(X_test,Y_test)\n",
    "# print(\"Get SubTrain length:\", len(subtrainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtrainloader = data.DataLoader(subtrainset,batch_size=1000, shuffle=True,num_workers=0)\n",
    "validloader = data.DataLoader(validset, batch_size=1000, shuffle=True, num_workers=0)\n",
    "testloader = data.DataLoader(testset, batch_size=1000, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch size: torch.Size([1000, 90])\n",
      "y_batch size: torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "X_batch,y_batch=next(iter(subtrainloader))\n",
    "print(\"X_batch size:\", X_batch.size())\n",
    "print(\"y_batch size:\", y_batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# get number of input features\n",
    "D_in=subtrainset.Xnp.shape[1]\n",
    "H=45\n",
    "# Regressionproblem\n",
    "D_out = 1\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    device = \"cuda\"   \n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(\"Running on device: \", device)\n",
    "net = torch.nn.Sequential(\n",
    "        torch.nn.Linear(D_in, H),  \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, D_out)\n",
    ")\n",
    "# convert everything to float precision. \n",
    "net = net.float()\n",
    "# move the model to device (i.e., cpu or gpu)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr = 0.00001,momentum = 0,weight_decay = 0)\n",
    "# Binary Cross Entropy Loss\n",
    "loss_fn = torch.nn.MSELoss() # MSE would be used to calculate SSE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ValidRMSE(net):\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    valid_accumulated_SSE = 0\n",
    "    valid_accumulated_N = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(validloader):            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            targets = targets.reshape((-1, 1))\n",
    "            outputs = net(inputs) \n",
    "            cn_loss = loss_fn(outputs, targets) * len(inputs) # SSE = MSE * N\n",
    "            valid_accumulated_N += len(inputs)\n",
    "            valid_accumulated_SSE += cn_loss\n",
    "    rmse = math.sqrt(valid_accumulated_SSE / valid_accumulated_N)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 100 Subtrain_RMSE = 10.858 Validation_RMSE = 10.889\n",
      "Epoch 0 Step 200 Subtrain_RMSE = 9.799 Validation_RMSE = 9.124\n",
      "Epoch 0 Step 300 Subtrain_RMSE = 9.125 Validation_RMSE = 8.896\n",
      "Epoch 0 Step 400 Subtrain_RMSE = 9.033 Validation_RMSE = 8.842\n",
      "Epoch 1 Step 500 Subtrain_RMSE = 8.914 Validation_RMSE = 8.930\n",
      "Epoch 1 Step 600 Subtrain_RMSE = 8.868 Validation_RMSE = 8.842\n",
      "Epoch 1 Step 700 Subtrain_RMSE = 8.815 Validation_RMSE = 8.735\n",
      "Epoch 1 Step 800 Subtrain_RMSE = 8.870 Validation_RMSE = 8.749\n",
      "Epoch 2 Step 900 Subtrain_RMSE = 8.808 Validation_RMSE = 8.750\n",
      "Epoch 2 Step 1000 Subtrain_RMSE = 8.779 Validation_RMSE = 8.932\n",
      "Epoch 2 Step 1100 Subtrain_RMSE = 8.746 Validation_RMSE = 8.671\n",
      "Epoch 2 Step 1200 Subtrain_RMSE = 8.751 Validation_RMSE = 8.701\n",
      "Epoch 3 Step 1300 Subtrain_RMSE = 8.750 Validation_RMSE = 8.700\n",
      "Epoch 3 Step 1400 Subtrain_RMSE = 8.695 Validation_RMSE = 8.639\n",
      "Epoch 3 Step 1500 Subtrain_RMSE = 8.669 Validation_RMSE = 8.659\n",
      "Epoch 3 Step 1600 Subtrain_RMSE = 8.755 Validation_RMSE = 8.638\n",
      "Epoch 4 Step 1700 Subtrain_RMSE = 8.674 Validation_RMSE = 8.649\n",
      "Epoch 4 Step 1800 Subtrain_RMSE = 8.584 Validation_RMSE = 8.695\n",
      "Epoch 4 Step 1900 Subtrain_RMSE = 8.699 Validation_RMSE = 8.631\n",
      "Epoch 4 Step 2000 Subtrain_RMSE = 8.635 Validation_RMSE = 8.641\n",
      "Epoch 5 Step 2100 Subtrain_RMSE = 8.655 Validation_RMSE = 8.621\n",
      "Epoch 5 Step 2200 Subtrain_RMSE = 8.598 Validation_RMSE = 8.613\n",
      "Epoch 5 Step 2300 Subtrain_RMSE = 8.664 Validation_RMSE = 8.598\n",
      "Epoch 5 Step 2400 Subtrain_RMSE = 8.635 Validation_RMSE = 8.724\n",
      "Epoch 5 Step 2500 Subtrain_RMSE = 8.599 Validation_RMSE = 8.608\n",
      "Epoch 6 Step 2600 Subtrain_RMSE = 8.595 Validation_RMSE = 8.611\n",
      "Epoch 6 Step 2700 Subtrain_RMSE = 8.585 Validation_RMSE = 8.610\n",
      "Epoch 6 Step 2800 Subtrain_RMSE = 8.577 Validation_RMSE = 8.587\n",
      "Epoch 6 Step 2900 Subtrain_RMSE = 8.612 Validation_RMSE = 8.624\n",
      "Epoch 7 Step 3000 Subtrain_RMSE = 8.577 Validation_RMSE = 8.676\n",
      "Epoch 7 Step 3100 Subtrain_RMSE = 8.556 Validation_RMSE = 8.580\n",
      "Epoch 7 Step 3200 Subtrain_RMSE = 8.562 Validation_RMSE = 8.644\n",
      "Epoch 7 Step 3300 Subtrain_RMSE = 8.563 Validation_RMSE = 8.575\n",
      "Epoch 8 Step 3400 Subtrain_RMSE = 8.515 Validation_RMSE = 8.625\n",
      "Epoch 8 Step 3500 Subtrain_RMSE = 8.544 Validation_RMSE = 8.601\n",
      "Epoch 8 Step 3600 Subtrain_RMSE = 8.568 Validation_RMSE = 8.592\n",
      "Epoch 8 Step 3700 Subtrain_RMSE = 8.561 Validation_RMSE = 8.552\n",
      "Epoch 9 Step 3800 Subtrain_RMSE = 8.540 Validation_RMSE = 8.626\n",
      "Epoch 9 Step 3900 Subtrain_RMSE = 8.525 Validation_RMSE = 8.601\n",
      "Epoch 9 Step 4000 Subtrain_RMSE = 8.554 Validation_RMSE = 8.583\n",
      "Epoch 9 Step 4100 Subtrain_RMSE = 8.534 Validation_RMSE = 8.553\n",
      "Epoch 10 Step 4200 Subtrain_RMSE = 8.525 Validation_RMSE = 8.607\n",
      "Epoch 10 Step 4300 Subtrain_RMSE = 8.503 Validation_RMSE = 8.563\n",
      "Epoch 10 Step 4400 Subtrain_RMSE = 8.467 Validation_RMSE = 8.607\n",
      "Epoch 10 Step 4500 Subtrain_RMSE = 8.519 Validation_RMSE = 8.542\n",
      "Epoch 11 Step 4600 Subtrain_RMSE = 8.536 Validation_RMSE = 8.558\n",
      "Epoch 11 Step 4700 Subtrain_RMSE = 8.501 Validation_RMSE = 8.638\n",
      "Epoch 11 Step 4800 Subtrain_RMSE = 8.492 Validation_RMSE = 8.586\n",
      "Epoch 11 Step 4900 Subtrain_RMSE = 8.521 Validation_RMSE = 8.564\n",
      "Epoch 11 Step 5000 Subtrain_RMSE = 8.463 Validation_RMSE = 8.554\n",
      "Epoch 12 Step 5100 Subtrain_RMSE = 8.449 Validation_RMSE = 8.568\n",
      "Epoch 12 Step 5200 Subtrain_RMSE = 8.457 Validation_RMSE = 8.562\n",
      "Epoch 12 Step 5300 Subtrain_RMSE = 8.521 Validation_RMSE = 8.611\n",
      "Epoch 12 Step 5400 Subtrain_RMSE = 8.459 Validation_RMSE = 8.572\n",
      "Epoch 13 Step 5500 Subtrain_RMSE = 8.471 Validation_RMSE = 8.570\n",
      "Epoch 13 Step 5600 Subtrain_RMSE = 8.406 Validation_RMSE = 8.612\n",
      "Epoch 13 Step 5700 Subtrain_RMSE = 8.452 Validation_RMSE = 8.558\n",
      "Epoch 13 Step 5800 Subtrain_RMSE = 8.546 Validation_RMSE = 8.573\n",
      "Epoch 14 Step 5900 Subtrain_RMSE = 8.444 Validation_RMSE = 8.579\n",
      "Epoch 14 Step 6000 Subtrain_RMSE = 8.443 Validation_RMSE = 8.599\n",
      "Epoch 14 Step 6100 Subtrain_RMSE = 8.468 Validation_RMSE = 8.571\n",
      "Epoch 14 Step 6200 Subtrain_RMSE = 8.481 Validation_RMSE = 8.610\n",
      "Epoch 15 Step 6300 Subtrain_RMSE = 8.442 Validation_RMSE = 8.555\n",
      "Epoch 15 Step 6400 Subtrain_RMSE = 8.421 Validation_RMSE = 8.581\n",
      "Epoch 15 Step 6500 Subtrain_RMSE = 8.465 Validation_RMSE = 8.572\n",
      "Epoch 15 Step 6600 Subtrain_RMSE = 8.438 Validation_RMSE = 8.647\n",
      "Epoch 16 Step 6700 Subtrain_RMSE = 8.432 Validation_RMSE = 8.552\n",
      "Epoch 16 Step 6800 Subtrain_RMSE = 8.414 Validation_RMSE = 8.607\n",
      "Epoch 16 Step 6900 Subtrain_RMSE = 8.387 Validation_RMSE = 8.593\n",
      "Epoch 16 Step 7000 Subtrain_RMSE = 8.493 Validation_RMSE = 8.544\n",
      "Epoch 16 Step 7100 Subtrain_RMSE = 8.413 Validation_RMSE = 8.577\n",
      "Epoch 17 Step 7200 Subtrain_RMSE = 8.360 Validation_RMSE = 8.563\n",
      "Epoch 17 Step 7300 Subtrain_RMSE = 8.428 Validation_RMSE = 8.570\n",
      "Epoch 17 Step 7400 Subtrain_RMSE = 8.395 Validation_RMSE = 8.581\n",
      "Epoch 17 Step 7500 Subtrain_RMSE = 8.491 Validation_RMSE = 8.591\n",
      "Epoch 18 Step 7600 Subtrain_RMSE = 8.359 Validation_RMSE = 8.574\n",
      "Epoch 18 Step 7700 Subtrain_RMSE = 8.455 Validation_RMSE = 8.610\n",
      "Epoch 18 Step 7800 Subtrain_RMSE = 8.363 Validation_RMSE = 8.565\n",
      "Epoch 18 Step 7900 Subtrain_RMSE = 8.442 Validation_RMSE = 8.554\n",
      "Epoch 19 Step 8000 Subtrain_RMSE = 8.406 Validation_RMSE = 8.593\n",
      "Epoch 19 Step 8100 Subtrain_RMSE = 8.408 Validation_RMSE = 8.561\n",
      "Epoch 19 Step 8200 Subtrain_RMSE = 8.371 Validation_RMSE = 8.592\n",
      "Epoch 19 Step 8300 Subtrain_RMSE = 8.442 Validation_RMSE = 8.563\n",
      "Epoch 20 Step 8400 Subtrain_RMSE = 8.350 Validation_RMSE = 8.586\n",
      "Epoch 20 Step 8500 Subtrain_RMSE = 8.350 Validation_RMSE = 8.588\n",
      "Epoch 20 Step 8600 Subtrain_RMSE = 8.418 Validation_RMSE = 8.579\n",
      "Epoch 20 Step 8700 Subtrain_RMSE = 8.461 Validation_RMSE = 8.597\n",
      "Epoch 21 Step 8800 Subtrain_RMSE = 8.350 Validation_RMSE = 8.571\n",
      "Epoch 21 Step 8900 Subtrain_RMSE = 8.309 Validation_RMSE = 8.595\n",
      "Epoch 21 Step 9000 Subtrain_RMSE = 8.400 Validation_RMSE = 8.629\n",
      "Epoch 21 Step 9100 Subtrain_RMSE = 8.404 Validation_RMSE = 8.593\n",
      "Epoch 22 Step 9200 Subtrain_RMSE = 8.423 Validation_RMSE = 8.582\n",
      "Epoch 22 Step 9300 Subtrain_RMSE = 8.343 Validation_RMSE = 8.597\n",
      "Epoch 22 Step 9400 Subtrain_RMSE = 8.362 Validation_RMSE = 8.620\n",
      "Epoch 22 Step 9500 Subtrain_RMSE = 8.391 Validation_RMSE = 8.573\n",
      "Best Step: 4500\n",
      "Early stop at: 9501\n"
     ]
    }
   ],
   "source": [
    "nepoch = 100 \n",
    "step_count = 0 # batch number\n",
    "log_interval = 100\n",
    "subtrain_accumulated_SSE = 0\n",
    "subtrain_accumulated_N = 0\n",
    "\n",
    "validation_minloss = 999999\n",
    "best_net = copy.deepcopy(net)\n",
    "best_step_count = 0\n",
    "earlystop_waiting = 0\n",
    "\n",
    "batch_list=[]\n",
    "subtrain_rmse_list=[]\n",
    "valid_rmse_list=[]\n",
    "\n",
    "for epoch_id in range(0, nepoch):\n",
    "    early_stop=False\n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "        #reshape target to two-dimensional array\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        step_count += 1\n",
    "        net.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)        \n",
    "        loss = loss_fn(outputs, targets) * len(inputs)\n",
    "        \n",
    "        subtrain_accumulated_SSE += loss.item()\n",
    "        subtrain_accumulated_N += len(inputs)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        earlystop_waiting+=1\n",
    "        if step_count % log_interval == 0:\n",
    "            subtrain_rmse = math.sqrt(subtrain_accumulated_SSE / subtrain_accumulated_N)\n",
    "            batch_list.append(step_count)\n",
    "            subtrain_rmse_list.append(subtrain_rmse)\n",
    "            subtrain_accumulated_SSE = 0\n",
    "            subtrain_accumulated_N = 0\n",
    "            valid_rmse = calculate_ValidRMSE(net)\n",
    "            valid_rmse_list.append(valid_rmse)\n",
    "            print(\"Epoch %d Step %d Subtrain_RMSE = %.3f Validation_RMSE = %.3f\" % (epoch_id, step_count, subtrain_rmse, valid_rmse))\n",
    "            if(valid_rmse<validation_minloss):\n",
    "                validation_minloss=valid_rmse\n",
    "                best_net=copy.deepcopy(net)\n",
    "                best_step_count=step_count\n",
    "                earlystop_waiting=0\n",
    "        if earlystop_waiting>5000:\n",
    "            early_stop=True\n",
    "            break;\n",
    "    if(early_stop):\n",
    "        print(\"Best Step:\", best_step_count)\n",
    "        print(\"Early stop at:\", step_count)\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Q2 Line Chart\n",
    "plt.plot(batch_list,subtrain_rmse_list,label='Subtrain')\n",
    "plt.plot(batch_list,valid_rmse_list,label='Valid')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Batch V.S. RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING RMSE: 8.851566378667508\n"
     ]
    }
   ],
   "source": [
    "test_accumulated_SSE = 0\n",
    "test_accumulated_N = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):            \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        outputs = best_net(inputs)        \n",
    "        cn_loss = loss_fn(outputs, targets) * len(inputs)\n",
    "        test_accumulated_N += len(inputs)\n",
    "        test_accumulated_SSE += cn_loss\n",
    "\n",
    "rmse = math.sqrt(test_accumulated_SSE / test_accumulated_N)\n",
    "print(\"TESTING RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2解釋：  \n",
    "從上方的折線圖可看出，一開始不論是subtrain的RMSE還是validation的RMSE都減少得很快，但大概從第2000個batch開始時，減少的速度就開始放緩。  \n",
    "到了後期（約從第4000個batch之後），subtrain的RMSE有繼續下降，但validation的RMSE卻沒有改善，且兩者的差距也有擴大，可以看到有一點overfitting的情況發生。\n",
    "最後在Test RMSE的表現上，約為8.85，比Q1中OLS模型的表現還要來得好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3 (10%)\n",
    "重複上題步驟，使用H = 90與180。無須畫訓練過程的RMSE。列出這兩個Test RMSE。討論H = 45, 90, 180的Test RMSE。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(net,showsuboutcome):\n",
    "    nepoch = 100 \n",
    "    step_count = 0 # batch number\n",
    "    log_interval = 100\n",
    "    subtrain_accumulated_SSE = 0\n",
    "    subtrain_accumulated_N = 0\n",
    "\n",
    "    validation_minloss = 999999\n",
    "    best_net = copy.deepcopy(net)\n",
    "    best_step_count = 0\n",
    "    earlystop_waiting = 0\n",
    "    \n",
    "    for epoch_id in range(0, nepoch):\n",
    "        early_stop=False\n",
    "        for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "            #reshape target to two-dimensional array\n",
    "            targets = targets.reshape((-1, 1))\n",
    "            step_count += 1\n",
    "            net.train()\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)        \n",
    "            loss = loss_fn(outputs, targets) * len(inputs)\n",
    "\n",
    "            subtrain_accumulated_SSE += loss\n",
    "            subtrain_accumulated_N += len(inputs)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            earlystop_waiting+=1\n",
    "            if step_count % log_interval == 0:\n",
    "                subtrain_rmse = math.sqrt(subtrain_accumulated_SSE / subtrain_accumulated_N)\n",
    "                subtrain_accumulated_SSE = 0\n",
    "                subtrain_accumulated_N = 0\n",
    "                valid_rmse = calculate_ValidRMSE(net)\n",
    "                if showsuboutcome:\n",
    "                    print(\"Epoch %d Step %d Subtrain_RMSE = %.3f Validation_RMSE = %.3f\" % (epoch_id, step_count, subtrain_rmse, valid_rmse))\n",
    "                if(valid_rmse<validation_minloss):\n",
    "                    validation_minloss=valid_rmse\n",
    "                    best_net=copy.deepcopy(net)\n",
    "                    best_step_count=step_count\n",
    "                    earlystop_waiting=0\n",
    "            if earlystop_waiting>5000:\n",
    "                early_stop=True\n",
    "                break;\n",
    "        if(early_stop):\n",
    "            print(\"EARLY STOP AT:\", step_count)\n",
    "            break;\n",
    "    return best_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(best_net):\n",
    "    test_accumulated_SSE = 0\n",
    "    test_accumulated_N = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            targets = targets.reshape((-1, 1))\n",
    "            outputs = best_net(inputs)        \n",
    "            cn_loss = loss_fn(outputs, targets) * len(inputs)\n",
    "            test_accumulated_N += len(inputs)\n",
    "            test_accumulated_SSE += cn_loss\n",
    "\n",
    "    rmse = math.sqrt(test_accumulated_SSE / test_accumulated_N)\n",
    "    print(\"TESTING RMSE:\", rmse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNet(H):\n",
    "    # get number of input features\n",
    "    D_in=subtrainset.Xnp.shape[1]\n",
    "    # Regressionproblem\n",
    "    D_out = 1\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        device = \"cuda\"   \n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    print(\"Running on device: \", device)\n",
    "    net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(D_in, H),  \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, D_out)\n",
    "    )\n",
    "    # convert everything to float precision. \n",
    "    net = net.float()\n",
    "    # move the model to device (i.e., cpu or gpu)\n",
    "    net = net.to(device)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device:  cpu\n",
      "EARLY STOP AT: 10801\n",
      "TESTING RMSE: 8.880208810636596\n",
      "Testing RMSE For H=90: 8.880208810636596\n"
     ]
    }
   ],
   "source": [
    "net=createNet(90)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr = 0.00001,momentum = 0,weight_decay = 0)\n",
    "# Binary Cross Entropy Loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "best_net=training(net,False)\n",
    "testing_rmse=testing(best_net)\n",
    "print(\"Testing RMSE For H=90:\",testing_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device:  cpu\n",
      "EARLY STOP AT: 10001\n",
      "TESTING RMSE: 8.85771796121714\n",
      "Testing RMSE For H=180: 8.85771796121714\n"
     ]
    }
   ],
   "source": [
    "net=createNet(180)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr = 0.00001,momentum = 0,weight_decay = 0)\n",
    "# Binary Cross Entropy Loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "best_net=training(net,False)\n",
    "testing_rmse=testing(best_net)\n",
    "print(\"Testing RMSE For H=180:\",testing_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3解釋：  \n",
    "H=90時的Test RMSE為8.88左右，而H=180的Test RMSE則為8.86。在這題的例子當中，可以發現提高Hidden Nodes的數量至90與180並不會對於Test RMSE有顯著的提升，由此可以推知，這題的情境並不適合太複雜的網路。在選擇上，可以選擇H=45即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4 (15%)\n",
    "使用Q2的模型設定，考慮 H = 45, 90, 180與Weight Decay = 0.1, 0.2, 0.4的所有組合。模型估計後做表整理Test RMSE。討論H的選擇應為多少較合理?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device:  cpu\n",
      "EARLY STOP AT: 12001\n",
      "TESTING RMSE: 8.842680633917356\n",
      "[45, 0.1, 8.842680633917356]\n",
      "Running on device:  cpu\n",
      "EARLY STOP AT: 12101\n",
      "TESTING RMSE: 8.835577002067984\n",
      "[45, 0.2, 8.835577002067984]\n",
      "Running on device:  cpu\n",
      "EARLY STOP AT: 12001\n",
      "TESTING RMSE: 8.789432283887672\n",
      "[45, 0.4, 8.789432283887672]\n",
      "Running on device:  cpu\n",
      "EARLY STOP AT: 9601\n",
      "TESTING RMSE: 8.836640320744255\n",
      "[90, 0.1, 8.836640320744255]\n",
      "Running on device:  cpu\n",
      "EARLY STOP AT: 10001\n",
      "TESTING RMSE: 8.829555591360075\n",
      "[90, 0.2, 8.829555591360075]\n",
      "Running on device:  cpu\n",
      "EARLY STOP AT: 11101\n",
      "TESTING RMSE: 8.896567773689776\n",
      "[90, 0.4, 8.896567773689776]\n",
      "Running on device:  cpu\n",
      "EARLY STOP AT: 9601\n",
      "TESTING RMSE: 8.856588689106422\n",
      "[180, 0.1, 8.856588689106422]\n",
      "Running on device:  cpu\n",
      "EARLY STOP AT: 8901\n",
      "TESTING RMSE: 8.847400572326713\n",
      "[180, 0.2, 8.847400572326713]\n",
      "Running on device:  cpu\n",
      "EARLY STOP AT: 8301\n",
      "TESTING RMSE: 8.808302725236802\n",
      "[180, 0.4, 8.808302725236802]\n"
     ]
    }
   ],
   "source": [
    "Outcome_list=[]\n",
    "H_list=[45, 90, 180]\n",
    "WeightDecay_list=[0.1, 0.2, 0.4]\n",
    "\n",
    "for i in range(len(H_list)):\n",
    "    for j in range(len(WeightDecay_list)):\n",
    "        net=createNet(H_list[i])\n",
    "        \n",
    "        # define the optimizer\n",
    "        optimizer = torch.optim.SGD(net.parameters(),lr = 0.00001, momentum = 0, weight_decay = WeightDecay_list[j])\n",
    "        # Binary Cross Entropy Loss\n",
    "        loss_fn = torch.nn.MSELoss() \n",
    "\n",
    "        best_net=training(net,False)\n",
    "        testing_rmse=testing(best_net)\n",
    "        temp_outcome=[H_list[i],WeightDecay_list[j],testing_rmse]\n",
    "        print(temp_outcome)\n",
    "        Outcome_list.append(temp_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>Weight Decay</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8.842681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8.835577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8.789432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8.836640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8.829556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8.896568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>180</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8.856589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>180</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8.847401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>180</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8.808303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     H  Weight Decay      RMSE\n",
       "0   45           0.1  8.842681\n",
       "1   45           0.2  8.835577\n",
       "2   45           0.4  8.789432\n",
       "3   90           0.1  8.836640\n",
       "4   90           0.2  8.829556\n",
       "5   90           0.4  8.896568\n",
       "6  180           0.1  8.856589\n",
       "7  180           0.2  8.847401\n",
       "8  180           0.4  8.808303"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(Outcome_list)\n",
    "df=pd.DataFrame(Outcome_list,columns = ['H','Weight Decay','RMSE',])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4解釋：  \n",
    "各H和Weight Decay的對應RMSE如上表格所述，表現最佳的是在H=45且Weight Decay=0.4的情況。  \n",
    "若是將H=45所對應的三個Weight Decay組合的RMSE取平均，約為(8.842681+8.835577+8.789432)/3=8.82，H=90的RMSE平均則約為8.85，H=180的RMSE平均約為8.84，由此結果可推知，H選擇為45可能會有較好的表現。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5 MLP with Dropout (15%)\n",
    "建構一個有Dropout的四層Hidden Layer的MLP。此模型由輸入層開始，第一層由90個Input Features通過線性層轉換為H個Hidden Nodes，通過ReLu Activation Function，之後對Hidden Unit Dropout，機率為0.5。後面各Hidden Lyaer均在ReLu後有Dropout，機率皆為0.5。最後通過一個線性層輸出。所有Hidden Layer的寬度都為H。\n",
    "\n",
    "令H= 90, 使用Adaptive Moment Estimation (Adam)更新參數，設Learning Rate = 0.001，無Weight Decay與Momentum，其他參數使用預設值。畫出模型訓練過程中的Training與Validation RMSE，列出Test RMSE。 並討論訓練過程中Training與Validation RMSE的圖形意義。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateNetwithDropout(H):\n",
    "    # get number of input features\n",
    "    D_in=subtrainset.Xnp.shape[1]\n",
    "    # Regressionproblem\n",
    "    D_out = 1\n",
    "    dropout = 0.5\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        device = \"cuda\"   \n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    print(\"Running on device: \", device)\n",
    "    net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(D_in, H),  \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(H, D_out)\n",
    "    )\n",
    "    # convert everything to float precision. \n",
    "    net = net.float()\n",
    "    # move the model to device (i.e., cpu or gpu)\n",
    "    net = net.to(device)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device:  cpu\n",
      "Epoch 0 Step 100 Subtrain_RMSE = 10.597 Validation_RMSE = 9.779\n",
      "Epoch 0 Step 200 Subtrain_RMSE = 9.583 Validation_RMSE = 9.405\n",
      "Epoch 0 Step 300 Subtrain_RMSE = 9.379 Validation_RMSE = 9.254\n",
      "Epoch 0 Step 400 Subtrain_RMSE = 9.312 Validation_RMSE = 9.171\n",
      "Epoch 1 Step 500 Subtrain_RMSE = 9.217 Validation_RMSE = 9.138\n",
      "Epoch 1 Step 600 Subtrain_RMSE = 9.094 Validation_RMSE = 9.105\n",
      "Epoch 1 Step 700 Subtrain_RMSE = 9.215 Validation_RMSE = 9.065\n",
      "Epoch 1 Step 800 Subtrain_RMSE = 9.145 Validation_RMSE = 9.064\n",
      "Epoch 2 Step 900 Subtrain_RMSE = 9.145 Validation_RMSE = 9.041\n",
      "Epoch 2 Step 1000 Subtrain_RMSE = 9.031 Validation_RMSE = 9.023\n",
      "Epoch 2 Step 1100 Subtrain_RMSE = 9.104 Validation_RMSE = 9.013\n",
      "Epoch 2 Step 1200 Subtrain_RMSE = 9.076 Validation_RMSE = 8.990\n",
      "Epoch 3 Step 1300 Subtrain_RMSE = 9.006 Validation_RMSE = 8.988\n",
      "Epoch 3 Step 1400 Subtrain_RMSE = 9.051 Validation_RMSE = 8.991\n",
      "Epoch 3 Step 1500 Subtrain_RMSE = 9.009 Validation_RMSE = 8.962\n",
      "Epoch 3 Step 1600 Subtrain_RMSE = 9.019 Validation_RMSE = 8.927\n",
      "Epoch 4 Step 1700 Subtrain_RMSE = 9.028 Validation_RMSE = 8.940\n",
      "Epoch 4 Step 1800 Subtrain_RMSE = 8.990 Validation_RMSE = 8.953\n",
      "Epoch 4 Step 1900 Subtrain_RMSE = 8.976 Validation_RMSE = 8.963\n",
      "Epoch 4 Step 2000 Subtrain_RMSE = 9.032 Validation_RMSE = 8.945\n",
      "Epoch 5 Step 2100 Subtrain_RMSE = 8.995 Validation_RMSE = 8.940\n",
      "Epoch 5 Step 2200 Subtrain_RMSE = 8.972 Validation_RMSE = 8.937\n",
      "Epoch 5 Step 2300 Subtrain_RMSE = 8.955 Validation_RMSE = 8.923\n",
      "Epoch 5 Step 2400 Subtrain_RMSE = 8.945 Validation_RMSE = 8.913\n",
      "Epoch 5 Step 2500 Subtrain_RMSE = 8.980 Validation_RMSE = 8.923\n",
      "Epoch 6 Step 2600 Subtrain_RMSE = 8.908 Validation_RMSE = 8.946\n",
      "Epoch 6 Step 2700 Subtrain_RMSE = 8.955 Validation_RMSE = 8.914\n",
      "Epoch 6 Step 2800 Subtrain_RMSE = 9.001 Validation_RMSE = 8.888\n",
      "Epoch 6 Step 2900 Subtrain_RMSE = 8.925 Validation_RMSE = 8.899\n",
      "Epoch 7 Step 3000 Subtrain_RMSE = 8.970 Validation_RMSE = 8.917\n",
      "Epoch 7 Step 3100 Subtrain_RMSE = 8.864 Validation_RMSE = 8.900\n",
      "Epoch 7 Step 3200 Subtrain_RMSE = 8.940 Validation_RMSE = 8.909\n",
      "Epoch 7 Step 3300 Subtrain_RMSE = 8.978 Validation_RMSE = 8.898\n",
      "Epoch 8 Step 3400 Subtrain_RMSE = 8.964 Validation_RMSE = 8.907\n",
      "Epoch 8 Step 3500 Subtrain_RMSE = 8.948 Validation_RMSE = 8.915\n",
      "Epoch 8 Step 3600 Subtrain_RMSE = 8.940 Validation_RMSE = 8.889\n",
      "Epoch 8 Step 3700 Subtrain_RMSE = 8.878 Validation_RMSE = 8.880\n",
      "Epoch 9 Step 3800 Subtrain_RMSE = 8.862 Validation_RMSE = 8.890\n",
      "Epoch 9 Step 3900 Subtrain_RMSE = 8.899 Validation_RMSE = 8.886\n",
      "Epoch 9 Step 4000 Subtrain_RMSE = 8.918 Validation_RMSE = 8.876\n",
      "Epoch 9 Step 4100 Subtrain_RMSE = 8.952 Validation_RMSE = 8.898\n",
      "Epoch 10 Step 4200 Subtrain_RMSE = 8.950 Validation_RMSE = 8.867\n",
      "Epoch 10 Step 4300 Subtrain_RMSE = 8.862 Validation_RMSE = 8.887\n",
      "Epoch 10 Step 4400 Subtrain_RMSE = 8.927 Validation_RMSE = 8.885\n",
      "Epoch 10 Step 4500 Subtrain_RMSE = 8.910 Validation_RMSE = 8.891\n",
      "Epoch 11 Step 4600 Subtrain_RMSE = 8.940 Validation_RMSE = 8.844\n",
      "Epoch 11 Step 4700 Subtrain_RMSE = 8.885 Validation_RMSE = 8.892\n",
      "Epoch 11 Step 4800 Subtrain_RMSE = 8.887 Validation_RMSE = 8.889\n",
      "Epoch 11 Step 4900 Subtrain_RMSE = 8.928 Validation_RMSE = 8.883\n",
      "Epoch 11 Step 5000 Subtrain_RMSE = 8.896 Validation_RMSE = 8.891\n",
      "Epoch 12 Step 5100 Subtrain_RMSE = 8.897 Validation_RMSE = 8.881\n",
      "Epoch 12 Step 5200 Subtrain_RMSE = 8.932 Validation_RMSE = 8.891\n",
      "Epoch 12 Step 5300 Subtrain_RMSE = 8.857 Validation_RMSE = 8.893\n",
      "Epoch 12 Step 5400 Subtrain_RMSE = 8.850 Validation_RMSE = 8.873\n",
      "Epoch 13 Step 5500 Subtrain_RMSE = 8.922 Validation_RMSE = 8.895\n",
      "Epoch 13 Step 5600 Subtrain_RMSE = 8.854 Validation_RMSE = 8.864\n",
      "Epoch 13 Step 5700 Subtrain_RMSE = 8.871 Validation_RMSE = 8.886\n",
      "Epoch 13 Step 5800 Subtrain_RMSE = 8.894 Validation_RMSE = 8.891\n",
      "Epoch 14 Step 5900 Subtrain_RMSE = 8.875 Validation_RMSE = 8.876\n",
      "Epoch 14 Step 6000 Subtrain_RMSE = 8.919 Validation_RMSE = 8.880\n",
      "Epoch 14 Step 6100 Subtrain_RMSE = 8.857 Validation_RMSE = 8.867\n",
      "Epoch 14 Step 6200 Subtrain_RMSE = 8.880 Validation_RMSE = 8.858\n",
      "Epoch 15 Step 6300 Subtrain_RMSE = 8.896 Validation_RMSE = 8.881\n",
      "Epoch 15 Step 6400 Subtrain_RMSE = 8.809 Validation_RMSE = 8.864\n",
      "Epoch 15 Step 6500 Subtrain_RMSE = 8.868 Validation_RMSE = 8.860\n",
      "Epoch 15 Step 6600 Subtrain_RMSE = 8.908 Validation_RMSE = 8.867\n",
      "Epoch 16 Step 6700 Subtrain_RMSE = 8.871 Validation_RMSE = 8.865\n",
      "Epoch 16 Step 6800 Subtrain_RMSE = 8.905 Validation_RMSE = 8.892\n",
      "Epoch 16 Step 6900 Subtrain_RMSE = 8.807 Validation_RMSE = 8.863\n",
      "Epoch 16 Step 7000 Subtrain_RMSE = 8.904 Validation_RMSE = 8.871\n",
      "Epoch 16 Step 7100 Subtrain_RMSE = 8.852 Validation_RMSE = 8.868\n",
      "Epoch 17 Step 7200 Subtrain_RMSE = 8.869 Validation_RMSE = 8.861\n",
      "Epoch 17 Step 7300 Subtrain_RMSE = 8.820 Validation_RMSE = 8.888\n",
      "Epoch 17 Step 7400 Subtrain_RMSE = 8.850 Validation_RMSE = 8.873\n",
      "Epoch 17 Step 7500 Subtrain_RMSE = 8.907 Validation_RMSE = 8.876\n",
      "Epoch 18 Step 7600 Subtrain_RMSE = 8.842 Validation_RMSE = 8.873\n",
      "Epoch 18 Step 7700 Subtrain_RMSE = 8.857 Validation_RMSE = 8.868\n",
      "Epoch 18 Step 7800 Subtrain_RMSE = 8.840 Validation_RMSE = 8.876\n",
      "Epoch 18 Step 7900 Subtrain_RMSE = 8.874 Validation_RMSE = 8.848\n",
      "Epoch 19 Step 8000 Subtrain_RMSE = 8.851 Validation_RMSE = 8.852\n",
      "Epoch 19 Step 8100 Subtrain_RMSE = 8.864 Validation_RMSE = 8.881\n",
      "Epoch 19 Step 8200 Subtrain_RMSE = 8.861 Validation_RMSE = 8.877\n",
      "Epoch 19 Step 8300 Subtrain_RMSE = 8.843 Validation_RMSE = 8.844\n",
      "Epoch 20 Step 8400 Subtrain_RMSE = 8.868 Validation_RMSE = 8.843\n",
      "Epoch 20 Step 8500 Subtrain_RMSE = 8.757 Validation_RMSE = 8.879\n",
      "Epoch 20 Step 8600 Subtrain_RMSE = 8.867 Validation_RMSE = 8.844\n",
      "Epoch 20 Step 8700 Subtrain_RMSE = 8.913 Validation_RMSE = 8.856\n",
      "Epoch 21 Step 8800 Subtrain_RMSE = 8.876 Validation_RMSE = 8.840\n",
      "Epoch 21 Step 8900 Subtrain_RMSE = 8.843 Validation_RMSE = 8.854\n",
      "Epoch 21 Step 9000 Subtrain_RMSE = 8.839 Validation_RMSE = 8.839\n",
      "Epoch 21 Step 9100 Subtrain_RMSE = 8.824 Validation_RMSE = 8.835\n",
      "Epoch 22 Step 9200 Subtrain_RMSE = 8.875 Validation_RMSE = 8.864\n",
      "Epoch 22 Step 9300 Subtrain_RMSE = 8.861 Validation_RMSE = 8.860\n",
      "Epoch 22 Step 9400 Subtrain_RMSE = 8.802 Validation_RMSE = 8.857\n",
      "Epoch 22 Step 9500 Subtrain_RMSE = 8.901 Validation_RMSE = 8.836\n",
      "Epoch 22 Step 9600 Subtrain_RMSE = 8.838 Validation_RMSE = 8.860\n",
      "Epoch 23 Step 9700 Subtrain_RMSE = 8.770 Validation_RMSE = 8.868\n",
      "Epoch 23 Step 9800 Subtrain_RMSE = 8.849 Validation_RMSE = 8.853\n",
      "Epoch 23 Step 9900 Subtrain_RMSE = 8.840 Validation_RMSE = 8.850\n",
      "Epoch 23 Step 10000 Subtrain_RMSE = 8.838 Validation_RMSE = 8.856\n",
      "Epoch 24 Step 10100 Subtrain_RMSE = 8.868 Validation_RMSE = 8.834\n",
      "Epoch 24 Step 10200 Subtrain_RMSE = 8.836 Validation_RMSE = 8.845\n",
      "Epoch 24 Step 10300 Subtrain_RMSE = 8.834 Validation_RMSE = 8.860\n",
      "Epoch 24 Step 10400 Subtrain_RMSE = 8.805 Validation_RMSE = 8.833\n",
      "Epoch 25 Step 10500 Subtrain_RMSE = 8.848 Validation_RMSE = 8.831\n",
      "Epoch 25 Step 10600 Subtrain_RMSE = 8.784 Validation_RMSE = 8.856\n",
      "Epoch 25 Step 10700 Subtrain_RMSE = 8.811 Validation_RMSE = 8.852\n",
      "Epoch 25 Step 10800 Subtrain_RMSE = 8.846 Validation_RMSE = 8.858\n",
      "Epoch 26 Step 10900 Subtrain_RMSE = 8.909 Validation_RMSE = 8.847\n",
      "Epoch 26 Step 11000 Subtrain_RMSE = 8.855 Validation_RMSE = 8.873\n",
      "Epoch 26 Step 11100 Subtrain_RMSE = 8.830 Validation_RMSE = 8.849\n",
      "Epoch 26 Step 11200 Subtrain_RMSE = 8.813 Validation_RMSE = 8.858\n",
      "Epoch 27 Step 11300 Subtrain_RMSE = 8.797 Validation_RMSE = 8.829\n",
      "Epoch 27 Step 11400 Subtrain_RMSE = 8.792 Validation_RMSE = 8.851\n",
      "Epoch 27 Step 11500 Subtrain_RMSE = 8.835 Validation_RMSE = 8.841\n",
      "Epoch 27 Step 11600 Subtrain_RMSE = 8.834 Validation_RMSE = 8.846\n",
      "Epoch 27 Step 11700 Subtrain_RMSE = 8.856 Validation_RMSE = 8.848\n",
      "Epoch 28 Step 11800 Subtrain_RMSE = 8.795 Validation_RMSE = 8.837\n",
      "Epoch 28 Step 11900 Subtrain_RMSE = 8.831 Validation_RMSE = 8.866\n",
      "Epoch 28 Step 12000 Subtrain_RMSE = 8.851 Validation_RMSE = 8.820\n",
      "Epoch 28 Step 12100 Subtrain_RMSE = 8.795 Validation_RMSE = 8.838\n",
      "Epoch 29 Step 12200 Subtrain_RMSE = 8.815 Validation_RMSE = 8.837\n",
      "Epoch 29 Step 12300 Subtrain_RMSE = 8.837 Validation_RMSE = 8.855\n",
      "Epoch 29 Step 12400 Subtrain_RMSE = 8.791 Validation_RMSE = 8.865\n",
      "Epoch 29 Step 12500 Subtrain_RMSE = 8.826 Validation_RMSE = 8.830\n",
      "Epoch 30 Step 12600 Subtrain_RMSE = 8.859 Validation_RMSE = 8.861\n",
      "Epoch 30 Step 12700 Subtrain_RMSE = 8.790 Validation_RMSE = 8.853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Step 12800 Subtrain_RMSE = 8.809 Validation_RMSE = 8.846\n",
      "Epoch 30 Step 12900 Subtrain_RMSE = 8.875 Validation_RMSE = 8.827\n",
      "Epoch 31 Step 13000 Subtrain_RMSE = 8.783 Validation_RMSE = 8.846\n",
      "Epoch 31 Step 13100 Subtrain_RMSE = 8.781 Validation_RMSE = 8.824\n",
      "Epoch 31 Step 13200 Subtrain_RMSE = 8.900 Validation_RMSE = 8.861\n",
      "Epoch 31 Step 13300 Subtrain_RMSE = 8.831 Validation_RMSE = 8.844\n",
      "Epoch 32 Step 13400 Subtrain_RMSE = 8.759 Validation_RMSE = 8.839\n",
      "Epoch 32 Step 13500 Subtrain_RMSE = 8.834 Validation_RMSE = 8.856\n",
      "Epoch 32 Step 13600 Subtrain_RMSE = 8.766 Validation_RMSE = 8.839\n",
      "Epoch 32 Step 13700 Subtrain_RMSE = 8.828 Validation_RMSE = 8.851\n",
      "Epoch 33 Step 13800 Subtrain_RMSE = 8.838 Validation_RMSE = 8.829\n",
      "Epoch 33 Step 13900 Subtrain_RMSE = 8.818 Validation_RMSE = 8.878\n",
      "Epoch 33 Step 14000 Subtrain_RMSE = 8.879 Validation_RMSE = 8.832\n",
      "Epoch 33 Step 14100 Subtrain_RMSE = 8.778 Validation_RMSE = 8.841\n",
      "Epoch 33 Step 14200 Subtrain_RMSE = 8.816 Validation_RMSE = 8.855\n",
      "Epoch 34 Step 14300 Subtrain_RMSE = 8.830 Validation_RMSE = 8.844\n",
      "Epoch 34 Step 14400 Subtrain_RMSE = 8.806 Validation_RMSE = 8.836\n",
      "Epoch 34 Step 14500 Subtrain_RMSE = 8.830 Validation_RMSE = 8.864\n",
      "Epoch 34 Step 14600 Subtrain_RMSE = 8.790 Validation_RMSE = 8.850\n",
      "Epoch 35 Step 14700 Subtrain_RMSE = 8.774 Validation_RMSE = 8.837\n",
      "Epoch 35 Step 14800 Subtrain_RMSE = 8.796 Validation_RMSE = 8.834\n",
      "Epoch 35 Step 14900 Subtrain_RMSE = 8.862 Validation_RMSE = 8.841\n",
      "Epoch 35 Step 15000 Subtrain_RMSE = 8.820 Validation_RMSE = 8.828\n",
      "Epoch 36 Step 15100 Subtrain_RMSE = 8.818 Validation_RMSE = 8.848\n",
      "Epoch 36 Step 15200 Subtrain_RMSE = 8.803 Validation_RMSE = 8.816\n",
      "Epoch 36 Step 15300 Subtrain_RMSE = 8.797 Validation_RMSE = 8.834\n",
      "Epoch 36 Step 15400 Subtrain_RMSE = 8.797 Validation_RMSE = 8.850\n",
      "Epoch 37 Step 15500 Subtrain_RMSE = 8.852 Validation_RMSE = 8.834\n",
      "Epoch 37 Step 15600 Subtrain_RMSE = 8.834 Validation_RMSE = 8.832\n",
      "Epoch 37 Step 15700 Subtrain_RMSE = 8.770 Validation_RMSE = 8.847\n",
      "Epoch 37 Step 15800 Subtrain_RMSE = 8.816 Validation_RMSE = 8.848\n",
      "Epoch 38 Step 15900 Subtrain_RMSE = 8.771 Validation_RMSE = 8.827\n",
      "Epoch 38 Step 16000 Subtrain_RMSE = 8.855 Validation_RMSE = 8.830\n",
      "Epoch 38 Step 16100 Subtrain_RMSE = 8.722 Validation_RMSE = 8.849\n",
      "Epoch 38 Step 16200 Subtrain_RMSE = 8.798 Validation_RMSE = 8.803\n",
      "Epoch 38 Step 16300 Subtrain_RMSE = 8.847 Validation_RMSE = 8.870\n",
      "Epoch 39 Step 16400 Subtrain_RMSE = 8.795 Validation_RMSE = 8.838\n",
      "Epoch 39 Step 16500 Subtrain_RMSE = 8.794 Validation_RMSE = 8.850\n",
      "Epoch 39 Step 16600 Subtrain_RMSE = 8.763 Validation_RMSE = 8.835\n",
      "Epoch 39 Step 16700 Subtrain_RMSE = 8.838 Validation_RMSE = 8.818\n",
      "Epoch 40 Step 16800 Subtrain_RMSE = 8.803 Validation_RMSE = 8.826\n",
      "Epoch 40 Step 16900 Subtrain_RMSE = 8.838 Validation_RMSE = 8.824\n",
      "Epoch 40 Step 17000 Subtrain_RMSE = 8.780 Validation_RMSE = 8.836\n",
      "Epoch 40 Step 17100 Subtrain_RMSE = 8.826 Validation_RMSE = 8.830\n",
      "Epoch 41 Step 17200 Subtrain_RMSE = 8.814 Validation_RMSE = 8.834\n",
      "Epoch 41 Step 17300 Subtrain_RMSE = 8.758 Validation_RMSE = 8.844\n",
      "Epoch 41 Step 17400 Subtrain_RMSE = 8.791 Validation_RMSE = 8.833\n",
      "Epoch 41 Step 17500 Subtrain_RMSE = 8.821 Validation_RMSE = 8.822\n",
      "Epoch 42 Step 17600 Subtrain_RMSE = 8.822 Validation_RMSE = 8.835\n",
      "Epoch 42 Step 17700 Subtrain_RMSE = 8.768 Validation_RMSE = 8.849\n",
      "Epoch 42 Step 17800 Subtrain_RMSE = 8.794 Validation_RMSE = 8.830\n",
      "Epoch 42 Step 17900 Subtrain_RMSE = 8.794 Validation_RMSE = 8.828\n",
      "Epoch 43 Step 18000 Subtrain_RMSE = 8.820 Validation_RMSE = 8.821\n",
      "Epoch 43 Step 18100 Subtrain_RMSE = 8.832 Validation_RMSE = 8.814\n",
      "Epoch 43 Step 18200 Subtrain_RMSE = 8.788 Validation_RMSE = 8.841\n",
      "Epoch 43 Step 18300 Subtrain_RMSE = 8.768 Validation_RMSE = 8.833\n",
      "Epoch 44 Step 18400 Subtrain_RMSE = 8.810 Validation_RMSE = 8.822\n",
      "Epoch 44 Step 18500 Subtrain_RMSE = 8.788 Validation_RMSE = 8.837\n",
      "Epoch 44 Step 18600 Subtrain_RMSE = 8.822 Validation_RMSE = 8.830\n",
      "Epoch 44 Step 18700 Subtrain_RMSE = 8.800 Validation_RMSE = 8.810\n",
      "Epoch 44 Step 18800 Subtrain_RMSE = 8.754 Validation_RMSE = 8.850\n",
      "Epoch 45 Step 18900 Subtrain_RMSE = 8.732 Validation_RMSE = 8.808\n",
      "Epoch 45 Step 19000 Subtrain_RMSE = 8.799 Validation_RMSE = 8.830\n",
      "Epoch 45 Step 19100 Subtrain_RMSE = 8.835 Validation_RMSE = 8.827\n",
      "Epoch 45 Step 19200 Subtrain_RMSE = 8.800 Validation_RMSE = 8.833\n",
      "Epoch 46 Step 19300 Subtrain_RMSE = 8.790 Validation_RMSE = 8.821\n",
      "Epoch 46 Step 19400 Subtrain_RMSE = 8.768 Validation_RMSE = 8.843\n",
      "Epoch 46 Step 19500 Subtrain_RMSE = 8.809 Validation_RMSE = 8.842\n",
      "Epoch 46 Step 19600 Subtrain_RMSE = 8.804 Validation_RMSE = 8.830\n",
      "Epoch 47 Step 19700 Subtrain_RMSE = 8.772 Validation_RMSE = 8.857\n",
      "Epoch 47 Step 19800 Subtrain_RMSE = 8.772 Validation_RMSE = 8.840\n",
      "Epoch 47 Step 19900 Subtrain_RMSE = 8.817 Validation_RMSE = 8.837\n",
      "Epoch 47 Step 20000 Subtrain_RMSE = 8.836 Validation_RMSE = 8.826\n",
      "Epoch 48 Step 20100 Subtrain_RMSE = 8.735 Validation_RMSE = 8.851\n",
      "Epoch 48 Step 20200 Subtrain_RMSE = 8.784 Validation_RMSE = 8.823\n",
      "Epoch 48 Step 20300 Subtrain_RMSE = 8.758 Validation_RMSE = 8.833\n",
      "Epoch 48 Step 20400 Subtrain_RMSE = 8.781 Validation_RMSE = 8.830\n",
      "Epoch 49 Step 20500 Subtrain_RMSE = 8.852 Validation_RMSE = 8.827\n",
      "Epoch 49 Step 20600 Subtrain_RMSE = 8.781 Validation_RMSE = 8.827\n",
      "Epoch 49 Step 20700 Subtrain_RMSE = 8.852 Validation_RMSE = 8.819\n",
      "Epoch 49 Step 20800 Subtrain_RMSE = 8.755 Validation_RMSE = 8.809\n",
      "Epoch 49 Step 20900 Subtrain_RMSE = 8.777 Validation_RMSE = 8.816\n",
      "Epoch 50 Step 21000 Subtrain_RMSE = 8.737 Validation_RMSE = 8.816\n",
      "Epoch 50 Step 21100 Subtrain_RMSE = 8.787 Validation_RMSE = 8.829\n",
      "Epoch 50 Step 21200 Subtrain_RMSE = 8.839 Validation_RMSE = 8.817\n",
      "Best Step: 16200\n",
      "Early stop at: 21201\n"
     ]
    }
   ],
   "source": [
    "net=CreateNetwithDropout(90)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)\n",
    "# Binary Cross Entropy Loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "nepoch = 100 \n",
    "step_count = 0 # batch number\n",
    "log_interval = 100\n",
    "subtrain_accumulated_SSE = 0\n",
    "subtrain_accumulated_N = 0\n",
    "\n",
    "validation_minloss = 999999\n",
    "best_net = copy.deepcopy(net)\n",
    "best_step_count = 0\n",
    "earlystop_waiting = 0\n",
    "\n",
    "batch_list=[]\n",
    "subtrain_rmse_list=[]\n",
    "valid_rmse_list=[]\n",
    "\n",
    "for epoch_id in range(0, nepoch):\n",
    "    early_stop=False\n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "        #reshape target to two-dimensional array\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        step_count += 1\n",
    "        net.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)        \n",
    "        loss = loss_fn(outputs, targets) * len(inputs)\n",
    "        \n",
    "        subtrain_accumulated_SSE += loss\n",
    "        subtrain_accumulated_N += len(inputs)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        earlystop_waiting+=1\n",
    "        if step_count % log_interval == 0:\n",
    "            subtrain_rmse = math.sqrt(subtrain_accumulated_SSE / subtrain_accumulated_N)\n",
    "            batch_list.append(step_count)\n",
    "            subtrain_rmse_list.append(subtrain_rmse)\n",
    "            subtrain_accumulated_SSE = 0\n",
    "            subtrain_accumulated_N = 0\n",
    "            valid_rmse = calculate_ValidRMSE(net)\n",
    "            valid_rmse_list.append(valid_rmse)\n",
    "            print(\"Epoch %d Step %d Subtrain_RMSE = %.3f Validation_RMSE = %.3f\" % (epoch_id, step_count, subtrain_rmse, valid_rmse))\n",
    "            if(valid_rmse<validation_minloss):\n",
    "                validation_minloss=valid_rmse\n",
    "                best_net=copy.deepcopy(net)\n",
    "                best_step_count=step_count\n",
    "                earlystop_waiting=0\n",
    "        if earlystop_waiting>5000:\n",
    "            early_stop=True\n",
    "            break;\n",
    "    if(early_stop):\n",
    "        print(\"Best Step:\", best_step_count)\n",
    "        print(\"Early stop at:\", step_count)\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Q5 Line Chart\n",
    "plt.plot(batch_list,subtrain_rmse_list,label='Subtrain')\n",
    "plt.plot(batch_list,valid_rmse_list,label='Valid')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Batch V.S. RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING RMSE: 9.04140611498747\n"
     ]
    }
   ],
   "source": [
    "test_accumulated_SSE = 0\n",
    "test_accumulated_N = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):            \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        outputs = best_net(inputs)        \n",
    "        cn_loss = loss_fn(outputs, targets) * len(inputs)\n",
    "        test_accumulated_N += len(inputs)\n",
    "        test_accumulated_SSE += cn_loss\n",
    "\n",
    "rmse = math.sqrt(test_accumulated_SSE / test_accumulated_N)\n",
    "print(\"TESTING RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5解釋：  \n",
    "有Dropout之後可以看見，subtrain的RMSE有非常密集、像是鋸齒狀的上上下下。  \n",
    "不過，subtrain和validation的RMSE表現也比較相近，可知overfitting的問題比SGD來的和緩。另外，在有dropout的情況下，需要訓練更多的batch才可以達到early-stopping。最終訓練的Test RMSE表現則約為9.04。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6 Explore Number of Hidden Units (10%)\n",
    "使用上題的模型，考慮H = 20, 180, 360。 討論H = 20, 45, 180, 360的Test RMSE。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device:  cpu\n",
      "EARLY STOP AT: 14101\n",
      "TESTING RMSE: 9.405636384029219\n",
      "[20, 9.405636384029219]\n",
      "Running on device:  cpu\n",
      "EARLY STOP AT: 18301\n",
      "TESTING RMSE: 9.154386675805007\n",
      "[45, 9.154386675805007]\n",
      "Running on device:  cpu\n",
      "EARLY STOP AT: 12001\n",
      "TESTING RMSE: 8.95589448126052\n",
      "[180, 8.95589448126052]\n",
      "Running on device:  cpu\n",
      "EARLY STOP AT: 24901\n",
      "TESTING RMSE: 9.010088458542553\n",
      "[360, 9.010088458542553]\n"
     ]
    }
   ],
   "source": [
    "H_list=[20, 45, 180, 360]\n",
    "Outcome_list=[]\n",
    "\n",
    "for i in range(len(H_list)):\n",
    "    net=CreateNetwithDropout(H_list[i])\n",
    "        \n",
    "    # define the optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)\n",
    "    # Binary Cross Entropy Loss\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    best_net=training(net,False)\n",
    "    testing_rmse=testing(best_net)\n",
    "    temp_outcome=[H_list[i],testing_rmse]\n",
    "    print(temp_outcome)\n",
    "    Outcome_list.append(temp_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>9.405636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>9.154387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180</td>\n",
       "      <td>8.955894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360</td>\n",
       "      <td>9.010088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     H      RMSE\n",
       "0   20  9.405636\n",
       "1   45  9.154387\n",
       "2  180  8.955894\n",
       "3  360  9.010088"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(Outcome_list)\n",
    "df=pd.DataFrame(Outcome_list,columns = ['H','RMSE'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6解釋：  \n",
    "各H對應RMSE如上表格所述，表現最佳的是在H=180的情況。\n",
    "由表格可知，在有使用dropout以及使用Adam更新參數的情況下，H設為180可能會有較好的RMSE表現；反之H設為20時的RMSE表現則明顯差於其他的H值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7 L2 + L1 Loss (15%)\n",
    "我們前面的小題皆是使用SSE，也就是L2 Loss。一個改善模型訓練的方式是使用多種類似的Loss，以線性組合的方式建構Loss Function。請使用Q5中的MLP with Dropout模型 (H = 90)，並以L2 + L1 Loss訓練模型。這個Loss的定義如下:\n",
    "\n",
    "$$\n",
    "loss(\\mathbf{y}, \\hat{\\mathbf{y}}) = z \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + (1 - z) \\sum_{i = 1}^n | y_i - \\hat{y}_i |,\n",
    "$$\n",
    "其中z為實數且$0 <=z <= 1$。\n",
    "\n",
    "使用z = 0.5。並以Adam訓練模型。畫出Training and Validation RMSE，並報告Test RMSE。注意這裡繪圖時應使用RMSE而不是這個特殊的Loss。\n",
    "\n",
    "另外，使用z = 0.0, 0.1, 0.9, 1.0訓練模型(不須提供訓練過程的Loss圖形)，統整各個z值下的Test RMSE並討論。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2PlusL1Loss(y,yhat,z):\n",
    "    return z*torch.sum((y-yhat)**2)+(1-z)*torch.sum(torch.abs(y-yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q7Train(net,z,showsuboutcome):\n",
    "    print(\"Z:\",z)\n",
    "    net=CreateNetwithDropout(90)\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)\n",
    "    mse = torch.nn.MSELoss()\n",
    "\n",
    "    nepoch = 100 \n",
    "    step_count = 0 # batch number\n",
    "    log_interval = 100\n",
    "    subtrain_accumulated_sse = 0\n",
    "    subtrain_accumulated_N = 0\n",
    "\n",
    "    validation_minrmse = 999999\n",
    "    best_net = copy.deepcopy(net)\n",
    "    best_step_count = 0\n",
    "    earlystop_waiting = 0\n",
    "\n",
    "    for epoch_id in range(0, nepoch):\n",
    "        early_stop=False\n",
    "        for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "            #reshape target to two-dimensional array\n",
    "            targets = targets.reshape((-1, 1))\n",
    "            step_count += 1\n",
    "            net.train()\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)        \n",
    "            loss = L2PlusL1Loss(outputs, targets, z)\n",
    "            sse = mse(outputs, targets) * len(inputs)\n",
    "\n",
    "            subtrain_accumulated_sse += sse\n",
    "            subtrain_accumulated_N += len(inputs)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            earlystop_waiting+=1\n",
    "            if step_count % log_interval == 0:\n",
    "                subtrain_rmse = math.sqrt(subtrain_accumulated_sse / subtrain_accumulated_N)\n",
    "                subtrain_accumulated_sse = 0\n",
    "                subtrain_accumulated_N = 0\n",
    "                valid_rmse = calculate_ValidRMSE(net)\n",
    "                if showsuboutcome:\n",
    "                    print(\"Epoch %d Step %d Subtrain_RMSE = %.3f Validation_RMSE = %.3f\" % (epoch_id, step_count, subtrain_rmse, valid_rmse))\n",
    "                if(valid_rmse<validation_minrmse):\n",
    "                    validation_minrmse=valid_rmse\n",
    "                    best_net=copy.deepcopy(net)\n",
    "                    best_step_count=step_count\n",
    "                    earlystop_waiting=0\n",
    "            if earlystop_waiting>5000:\n",
    "                early_stop=True\n",
    "                break;\n",
    "        if(early_stop):\n",
    "            print(\"Best Step:\", best_step_count)\n",
    "            print(\"Early stop at:\", step_count)\n",
    "            break;\n",
    "    return best_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device:  cpu\n",
      "Epoch 0 Step 100 Subtrain_RMSE = 10.576 Validation_RMSE = 9.883\n",
      "Epoch 0 Step 200 Subtrain_RMSE = 9.635 Validation_RMSE = 9.404\n",
      "Epoch 0 Step 300 Subtrain_RMSE = 9.370 Validation_RMSE = 9.272\n",
      "Epoch 0 Step 400 Subtrain_RMSE = 9.311 Validation_RMSE = 9.195\n",
      "Epoch 1 Step 500 Subtrain_RMSE = 9.219 Validation_RMSE = 9.128\n",
      "Epoch 1 Step 600 Subtrain_RMSE = 9.209 Validation_RMSE = 9.128\n",
      "Epoch 1 Step 700 Subtrain_RMSE = 9.161 Validation_RMSE = 9.067\n",
      "Epoch 1 Step 800 Subtrain_RMSE = 9.143 Validation_RMSE = 9.049\n",
      "Epoch 2 Step 900 Subtrain_RMSE = 9.066 Validation_RMSE = 9.067\n",
      "Epoch 2 Step 1000 Subtrain_RMSE = 9.101 Validation_RMSE = 9.016\n",
      "Epoch 2 Step 1100 Subtrain_RMSE = 9.073 Validation_RMSE = 8.999\n",
      "Epoch 2 Step 1200 Subtrain_RMSE = 9.093 Validation_RMSE = 8.995\n",
      "Epoch 3 Step 1300 Subtrain_RMSE = 9.028 Validation_RMSE = 9.001\n",
      "Epoch 3 Step 1400 Subtrain_RMSE = 9.044 Validation_RMSE = 8.967\n",
      "Epoch 3 Step 1500 Subtrain_RMSE = 9.040 Validation_RMSE = 8.968\n",
      "Epoch 3 Step 1600 Subtrain_RMSE = 9.031 Validation_RMSE = 8.970\n",
      "Epoch 4 Step 1700 Subtrain_RMSE = 9.002 Validation_RMSE = 8.963\n",
      "Epoch 4 Step 1800 Subtrain_RMSE = 9.014 Validation_RMSE = 8.963\n",
      "Epoch 4 Step 1900 Subtrain_RMSE = 8.956 Validation_RMSE = 8.954\n",
      "Epoch 4 Step 2000 Subtrain_RMSE = 9.051 Validation_RMSE = 8.966\n",
      "Epoch 5 Step 2100 Subtrain_RMSE = 8.966 Validation_RMSE = 8.957\n",
      "Epoch 5 Step 2200 Subtrain_RMSE = 8.946 Validation_RMSE = 8.942\n",
      "Epoch 5 Step 2300 Subtrain_RMSE = 8.944 Validation_RMSE = 8.955\n",
      "Epoch 5 Step 2400 Subtrain_RMSE = 8.982 Validation_RMSE = 8.927\n",
      "Epoch 5 Step 2500 Subtrain_RMSE = 9.028 Validation_RMSE = 8.913\n",
      "Epoch 6 Step 2600 Subtrain_RMSE = 8.951 Validation_RMSE = 8.923\n",
      "Epoch 6 Step 2700 Subtrain_RMSE = 8.887 Validation_RMSE = 8.922\n",
      "Epoch 6 Step 2800 Subtrain_RMSE = 8.995 Validation_RMSE = 8.940\n",
      "Epoch 6 Step 2900 Subtrain_RMSE = 8.968 Validation_RMSE = 8.934\n",
      "Epoch 7 Step 3000 Subtrain_RMSE = 8.909 Validation_RMSE = 8.911\n",
      "Epoch 7 Step 3100 Subtrain_RMSE = 8.943 Validation_RMSE = 8.907\n",
      "Epoch 7 Step 3200 Subtrain_RMSE = 8.922 Validation_RMSE = 8.923\n",
      "Epoch 7 Step 3300 Subtrain_RMSE = 8.993 Validation_RMSE = 8.895\n",
      "Epoch 8 Step 3400 Subtrain_RMSE = 8.981 Validation_RMSE = 8.915\n",
      "Epoch 8 Step 3500 Subtrain_RMSE = 8.892 Validation_RMSE = 8.885\n",
      "Epoch 8 Step 3600 Subtrain_RMSE = 8.897 Validation_RMSE = 8.884\n",
      "Epoch 8 Step 3700 Subtrain_RMSE = 8.920 Validation_RMSE = 8.893\n",
      "Epoch 9 Step 3800 Subtrain_RMSE = 8.950 Validation_RMSE = 8.895\n",
      "Epoch 9 Step 3900 Subtrain_RMSE = 8.939 Validation_RMSE = 8.874\n",
      "Epoch 9 Step 4000 Subtrain_RMSE = 8.895 Validation_RMSE = 8.871\n",
      "Epoch 9 Step 4100 Subtrain_RMSE = 8.929 Validation_RMSE = 8.871\n",
      "Epoch 10 Step 4200 Subtrain_RMSE = 8.849 Validation_RMSE = 8.881\n",
      "Epoch 10 Step 4300 Subtrain_RMSE = 8.881 Validation_RMSE = 8.873\n",
      "Epoch 10 Step 4400 Subtrain_RMSE = 8.899 Validation_RMSE = 8.900\n",
      "Epoch 10 Step 4500 Subtrain_RMSE = 8.914 Validation_RMSE = 8.892\n",
      "Epoch 11 Step 4600 Subtrain_RMSE = 8.935 Validation_RMSE = 8.899\n",
      "Epoch 11 Step 4700 Subtrain_RMSE = 8.857 Validation_RMSE = 8.890\n",
      "Epoch 11 Step 4800 Subtrain_RMSE = 8.945 Validation_RMSE = 8.905\n",
      "Epoch 11 Step 4900 Subtrain_RMSE = 8.865 Validation_RMSE = 8.886\n",
      "Epoch 11 Step 5000 Subtrain_RMSE = 8.933 Validation_RMSE = 8.864\n",
      "Epoch 12 Step 5100 Subtrain_RMSE = 8.854 Validation_RMSE = 8.881\n",
      "Epoch 12 Step 5200 Subtrain_RMSE = 8.910 Validation_RMSE = 8.864\n",
      "Epoch 12 Step 5300 Subtrain_RMSE = 8.893 Validation_RMSE = 8.880\n",
      "Epoch 12 Step 5400 Subtrain_RMSE = 8.889 Validation_RMSE = 8.859\n",
      "Epoch 13 Step 5500 Subtrain_RMSE = 8.912 Validation_RMSE = 8.875\n",
      "Epoch 13 Step 5600 Subtrain_RMSE = 8.900 Validation_RMSE = 8.857\n",
      "Epoch 13 Step 5700 Subtrain_RMSE = 8.907 Validation_RMSE = 8.875\n",
      "Epoch 13 Step 5800 Subtrain_RMSE = 8.849 Validation_RMSE = 8.885\n",
      "Epoch 14 Step 5900 Subtrain_RMSE = 8.885 Validation_RMSE = 8.884\n",
      "Epoch 14 Step 6000 Subtrain_RMSE = 8.855 Validation_RMSE = 8.849\n",
      "Epoch 14 Step 6100 Subtrain_RMSE = 8.876 Validation_RMSE = 8.866\n",
      "Epoch 14 Step 6200 Subtrain_RMSE = 8.875 Validation_RMSE = 8.882\n",
      "Epoch 15 Step 6300 Subtrain_RMSE = 8.875 Validation_RMSE = 8.869\n",
      "Epoch 15 Step 6400 Subtrain_RMSE = 8.968 Validation_RMSE = 8.858\n",
      "Epoch 15 Step 6500 Subtrain_RMSE = 8.838 Validation_RMSE = 8.868\n",
      "Epoch 15 Step 6600 Subtrain_RMSE = 8.834 Validation_RMSE = 8.859\n",
      "Epoch 16 Step 6700 Subtrain_RMSE = 8.874 Validation_RMSE = 8.847\n",
      "Epoch 16 Step 6800 Subtrain_RMSE = 8.812 Validation_RMSE = 8.881\n",
      "Epoch 16 Step 6900 Subtrain_RMSE = 8.861 Validation_RMSE = 8.869\n",
      "Epoch 16 Step 7000 Subtrain_RMSE = 8.913 Validation_RMSE = 8.893\n",
      "Epoch 16 Step 7100 Subtrain_RMSE = 8.866 Validation_RMSE = 8.857\n",
      "Epoch 17 Step 7200 Subtrain_RMSE = 8.837 Validation_RMSE = 8.854\n",
      "Epoch 17 Step 7300 Subtrain_RMSE = 8.876 Validation_RMSE = 8.857\n",
      "Epoch 17 Step 7400 Subtrain_RMSE = 8.882 Validation_RMSE = 8.864\n",
      "Epoch 17 Step 7500 Subtrain_RMSE = 8.864 Validation_RMSE = 8.890\n",
      "Epoch 18 Step 7600 Subtrain_RMSE = 8.861 Validation_RMSE = 8.862\n",
      "Epoch 18 Step 7700 Subtrain_RMSE = 8.860 Validation_RMSE = 8.889\n",
      "Epoch 18 Step 7800 Subtrain_RMSE = 8.904 Validation_RMSE = 8.870\n",
      "Epoch 18 Step 7900 Subtrain_RMSE = 8.823 Validation_RMSE = 8.883\n",
      "Epoch 19 Step 8000 Subtrain_RMSE = 8.824 Validation_RMSE = 8.880\n",
      "Epoch 19 Step 8100 Subtrain_RMSE = 8.821 Validation_RMSE = 8.873\n",
      "Epoch 19 Step 8200 Subtrain_RMSE = 8.867 Validation_RMSE = 8.858\n",
      "Epoch 19 Step 8300 Subtrain_RMSE = 8.914 Validation_RMSE = 8.878\n",
      "Epoch 20 Step 8400 Subtrain_RMSE = 8.846 Validation_RMSE = 8.856\n",
      "Epoch 20 Step 8500 Subtrain_RMSE = 8.798 Validation_RMSE = 8.859\n",
      "Epoch 20 Step 8600 Subtrain_RMSE = 8.878 Validation_RMSE = 8.845\n",
      "Epoch 20 Step 8700 Subtrain_RMSE = 8.857 Validation_RMSE = 8.857\n",
      "Epoch 21 Step 8800 Subtrain_RMSE = 8.882 Validation_RMSE = 8.871\n",
      "Epoch 21 Step 8900 Subtrain_RMSE = 8.785 Validation_RMSE = 8.847\n",
      "Epoch 21 Step 9000 Subtrain_RMSE = 8.861 Validation_RMSE = 8.873\n",
      "Epoch 21 Step 9100 Subtrain_RMSE = 8.886 Validation_RMSE = 8.857\n",
      "Epoch 22 Step 9200 Subtrain_RMSE = 8.825 Validation_RMSE = 8.861\n",
      "Epoch 22 Step 9300 Subtrain_RMSE = 8.780 Validation_RMSE = 8.855\n",
      "Epoch 22 Step 9400 Subtrain_RMSE = 8.875 Validation_RMSE = 8.846\n",
      "Epoch 22 Step 9500 Subtrain_RMSE = 8.848 Validation_RMSE = 8.891\n",
      "Epoch 22 Step 9600 Subtrain_RMSE = 8.865 Validation_RMSE = 8.844\n",
      "Epoch 23 Step 9700 Subtrain_RMSE = 8.834 Validation_RMSE = 8.864\n",
      "Epoch 23 Step 9800 Subtrain_RMSE = 8.862 Validation_RMSE = 8.834\n",
      "Epoch 23 Step 9900 Subtrain_RMSE = 8.873 Validation_RMSE = 8.858\n",
      "Epoch 23 Step 10000 Subtrain_RMSE = 8.801 Validation_RMSE = 8.850\n",
      "Epoch 24 Step 10100 Subtrain_RMSE = 8.843 Validation_RMSE = 8.866\n",
      "Epoch 24 Step 10200 Subtrain_RMSE = 8.870 Validation_RMSE = 8.872\n",
      "Epoch 24 Step 10300 Subtrain_RMSE = 8.794 Validation_RMSE = 8.852\n",
      "Epoch 24 Step 10400 Subtrain_RMSE = 8.835 Validation_RMSE = 8.828\n",
      "Epoch 25 Step 10500 Subtrain_RMSE = 8.828 Validation_RMSE = 8.872\n",
      "Epoch 25 Step 10600 Subtrain_RMSE = 8.822 Validation_RMSE = 8.859\n",
      "Epoch 25 Step 10700 Subtrain_RMSE = 8.795 Validation_RMSE = 8.878\n",
      "Epoch 25 Step 10800 Subtrain_RMSE = 8.906 Validation_RMSE = 8.859\n",
      "Epoch 26 Step 10900 Subtrain_RMSE = 8.797 Validation_RMSE = 8.856\n",
      "Epoch 26 Step 11000 Subtrain_RMSE = 8.794 Validation_RMSE = 8.872\n",
      "Epoch 26 Step 11100 Subtrain_RMSE = 8.849 Validation_RMSE = 8.855\n",
      "Epoch 26 Step 11200 Subtrain_RMSE = 8.833 Validation_RMSE = 8.864\n",
      "Epoch 27 Step 11300 Subtrain_RMSE = 8.869 Validation_RMSE = 8.867\n",
      "Epoch 27 Step 11400 Subtrain_RMSE = 8.803 Validation_RMSE = 8.860\n",
      "Epoch 27 Step 11500 Subtrain_RMSE = 8.830 Validation_RMSE = 8.850\n",
      "Epoch 27 Step 11600 Subtrain_RMSE = 8.842 Validation_RMSE = 8.876\n",
      "Epoch 27 Step 11700 Subtrain_RMSE = 8.830 Validation_RMSE = 8.855\n",
      "Epoch 28 Step 11800 Subtrain_RMSE = 8.840 Validation_RMSE = 8.856\n",
      "Epoch 28 Step 11900 Subtrain_RMSE = 8.834 Validation_RMSE = 8.853\n",
      "Epoch 28 Step 12000 Subtrain_RMSE = 8.835 Validation_RMSE = 8.869\n",
      "Epoch 28 Step 12100 Subtrain_RMSE = 8.793 Validation_RMSE = 8.833\n",
      "Epoch 29 Step 12200 Subtrain_RMSE = 8.843 Validation_RMSE = 8.835\n",
      "Epoch 29 Step 12300 Subtrain_RMSE = 8.820 Validation_RMSE = 8.849\n",
      "Epoch 29 Step 12400 Subtrain_RMSE = 8.783 Validation_RMSE = 8.846\n",
      "Epoch 29 Step 12500 Subtrain_RMSE = 8.839 Validation_RMSE = 8.855\n",
      "Epoch 30 Step 12600 Subtrain_RMSE = 8.822 Validation_RMSE = 8.845\n",
      "Epoch 30 Step 12700 Subtrain_RMSE = 8.825 Validation_RMSE = 8.885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Step 12800 Subtrain_RMSE = 8.813 Validation_RMSE = 8.829\n",
      "Epoch 30 Step 12900 Subtrain_RMSE = 8.845 Validation_RMSE = 8.891\n",
      "Epoch 31 Step 13000 Subtrain_RMSE = 8.840 Validation_RMSE = 8.883\n",
      "Epoch 31 Step 13100 Subtrain_RMSE = 8.815 Validation_RMSE = 8.849\n",
      "Epoch 31 Step 13200 Subtrain_RMSE = 8.824 Validation_RMSE = 8.839\n",
      "Epoch 31 Step 13300 Subtrain_RMSE = 8.816 Validation_RMSE = 8.852\n",
      "Epoch 32 Step 13400 Subtrain_RMSE = 8.757 Validation_RMSE = 8.877\n",
      "Epoch 32 Step 13500 Subtrain_RMSE = 8.833 Validation_RMSE = 8.841\n",
      "Epoch 32 Step 13600 Subtrain_RMSE = 8.827 Validation_RMSE = 8.858\n",
      "Epoch 32 Step 13700 Subtrain_RMSE = 8.862 Validation_RMSE = 8.854\n",
      "Epoch 33 Step 13800 Subtrain_RMSE = 8.778 Validation_RMSE = 8.842\n",
      "Epoch 33 Step 13900 Subtrain_RMSE = 8.762 Validation_RMSE = 8.858\n",
      "Epoch 33 Step 14000 Subtrain_RMSE = 8.835 Validation_RMSE = 8.841\n",
      "Epoch 33 Step 14100 Subtrain_RMSE = 8.859 Validation_RMSE = 8.851\n",
      "Epoch 33 Step 14200 Subtrain_RMSE = 8.806 Validation_RMSE = 8.821\n",
      "Epoch 34 Step 14300 Subtrain_RMSE = 8.840 Validation_RMSE = 8.830\n",
      "Epoch 34 Step 14400 Subtrain_RMSE = 8.746 Validation_RMSE = 8.825\n",
      "Epoch 34 Step 14500 Subtrain_RMSE = 8.837 Validation_RMSE = 8.828\n",
      "Epoch 34 Step 14600 Subtrain_RMSE = 8.824 Validation_RMSE = 8.837\n",
      "Epoch 35 Step 14700 Subtrain_RMSE = 8.805 Validation_RMSE = 8.841\n",
      "Epoch 35 Step 14800 Subtrain_RMSE = 8.843 Validation_RMSE = 8.856\n",
      "Epoch 35 Step 14900 Subtrain_RMSE = 8.766 Validation_RMSE = 8.843\n",
      "Epoch 35 Step 15000 Subtrain_RMSE = 8.892 Validation_RMSE = 8.828\n",
      "Epoch 36 Step 15100 Subtrain_RMSE = 8.761 Validation_RMSE = 8.828\n",
      "Epoch 36 Step 15200 Subtrain_RMSE = 8.737 Validation_RMSE = 8.846\n",
      "Epoch 36 Step 15300 Subtrain_RMSE = 8.825 Validation_RMSE = 8.823\n",
      "Epoch 36 Step 15400 Subtrain_RMSE = 8.831 Validation_RMSE = 8.844\n",
      "Epoch 37 Step 15500 Subtrain_RMSE = 8.896 Validation_RMSE = 8.817\n",
      "Epoch 37 Step 15600 Subtrain_RMSE = 8.801 Validation_RMSE = 8.825\n",
      "Epoch 37 Step 15700 Subtrain_RMSE = 8.786 Validation_RMSE = 8.843\n",
      "Epoch 37 Step 15800 Subtrain_RMSE = 8.731 Validation_RMSE = 8.859\n",
      "Epoch 38 Step 15900 Subtrain_RMSE = 8.883 Validation_RMSE = 8.844\n",
      "Epoch 38 Step 16000 Subtrain_RMSE = 8.762 Validation_RMSE = 8.862\n",
      "Epoch 38 Step 16100 Subtrain_RMSE = 8.821 Validation_RMSE = 8.841\n",
      "Epoch 38 Step 16200 Subtrain_RMSE = 8.796 Validation_RMSE = 8.837\n",
      "Epoch 38 Step 16300 Subtrain_RMSE = 8.830 Validation_RMSE = 8.835\n",
      "Epoch 39 Step 16400 Subtrain_RMSE = 8.832 Validation_RMSE = 8.828\n",
      "Epoch 39 Step 16500 Subtrain_RMSE = 8.788 Validation_RMSE = 8.846\n",
      "Epoch 39 Step 16600 Subtrain_RMSE = 8.774 Validation_RMSE = 8.873\n",
      "Epoch 39 Step 16700 Subtrain_RMSE = 8.819 Validation_RMSE = 8.840\n",
      "Epoch 40 Step 16800 Subtrain_RMSE = 8.777 Validation_RMSE = 8.825\n",
      "Epoch 40 Step 16900 Subtrain_RMSE = 8.821 Validation_RMSE = 8.835\n",
      "Epoch 40 Step 17000 Subtrain_RMSE = 8.774 Validation_RMSE = 8.851\n",
      "Epoch 40 Step 17100 Subtrain_RMSE = 8.847 Validation_RMSE = 8.835\n",
      "Epoch 41 Step 17200 Subtrain_RMSE = 8.840 Validation_RMSE = 8.835\n",
      "Epoch 41 Step 17300 Subtrain_RMSE = 8.841 Validation_RMSE = 8.840\n",
      "Epoch 41 Step 17400 Subtrain_RMSE = 8.788 Validation_RMSE = 8.829\n",
      "Epoch 41 Step 17500 Subtrain_RMSE = 8.793 Validation_RMSE = 8.823\n",
      "Epoch 42 Step 17600 Subtrain_RMSE = 8.767 Validation_RMSE = 8.820\n",
      "Epoch 42 Step 17700 Subtrain_RMSE = 8.774 Validation_RMSE = 8.843\n",
      "Epoch 42 Step 17800 Subtrain_RMSE = 8.834 Validation_RMSE = 8.835\n",
      "Epoch 42 Step 17900 Subtrain_RMSE = 8.797 Validation_RMSE = 8.849\n",
      "Epoch 43 Step 18000 Subtrain_RMSE = 8.847 Validation_RMSE = 8.829\n",
      "Epoch 43 Step 18100 Subtrain_RMSE = 8.856 Validation_RMSE = 8.848\n",
      "Epoch 43 Step 18200 Subtrain_RMSE = 8.735 Validation_RMSE = 8.846\n",
      "Epoch 43 Step 18300 Subtrain_RMSE = 8.792 Validation_RMSE = 8.849\n",
      "Epoch 44 Step 18400 Subtrain_RMSE = 8.772 Validation_RMSE = 8.827\n",
      "Epoch 44 Step 18500 Subtrain_RMSE = 8.794 Validation_RMSE = 8.844\n",
      "Epoch 44 Step 18600 Subtrain_RMSE = 8.779 Validation_RMSE = 8.859\n",
      "Epoch 44 Step 18700 Subtrain_RMSE = 8.798 Validation_RMSE = 8.856\n",
      "Epoch 44 Step 18800 Subtrain_RMSE = 8.813 Validation_RMSE = 8.846\n",
      "Epoch 45 Step 18900 Subtrain_RMSE = 8.836 Validation_RMSE = 8.845\n",
      "Epoch 45 Step 19000 Subtrain_RMSE = 8.749 Validation_RMSE = 8.853\n",
      "Epoch 45 Step 19100 Subtrain_RMSE = 8.753 Validation_RMSE = 8.867\n",
      "Epoch 45 Step 19200 Subtrain_RMSE = 8.852 Validation_RMSE = 8.824\n",
      "Epoch 46 Step 19300 Subtrain_RMSE = 8.775 Validation_RMSE = 8.825\n",
      "Epoch 46 Step 19400 Subtrain_RMSE = 8.761 Validation_RMSE = 8.839\n",
      "Epoch 46 Step 19500 Subtrain_RMSE = 8.807 Validation_RMSE = 8.824\n",
      "Epoch 46 Step 19600 Subtrain_RMSE = 8.824 Validation_RMSE = 8.833\n",
      "Epoch 47 Step 19700 Subtrain_RMSE = 8.807 Validation_RMSE = 8.838\n",
      "Epoch 47 Step 19800 Subtrain_RMSE = 8.783 Validation_RMSE = 8.834\n",
      "Epoch 47 Step 19900 Subtrain_RMSE = 8.780 Validation_RMSE = 8.827\n",
      "Epoch 47 Step 20000 Subtrain_RMSE = 8.795 Validation_RMSE = 8.836\n",
      "Epoch 48 Step 20100 Subtrain_RMSE = 8.768 Validation_RMSE = 8.834\n",
      "Epoch 48 Step 20200 Subtrain_RMSE = 8.744 Validation_RMSE = 8.837\n",
      "Epoch 48 Step 20300 Subtrain_RMSE = 8.824 Validation_RMSE = 8.830\n",
      "Epoch 48 Step 20400 Subtrain_RMSE = 8.838 Validation_RMSE = 8.834\n",
      "Epoch 49 Step 20500 Subtrain_RMSE = 8.787 Validation_RMSE = 8.827\n",
      "Best Step: 15500\n",
      "Early stop at: 20501\n"
     ]
    }
   ],
   "source": [
    "net=CreateNetwithDropout(90)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)\n",
    "mse = torch.nn.MSELoss()\n",
    "\n",
    "nepoch = 100 \n",
    "step_count = 0 # batch number\n",
    "log_interval = 100\n",
    "subtrain_accumulated_sse = 0\n",
    "subtrain_accumulated_N = 0\n",
    "\n",
    "validation_minrmse = 999999\n",
    "best_net = copy.deepcopy(net)\n",
    "best_step_count = 0\n",
    "earlystop_waiting = 0\n",
    "\n",
    "batch_list=[]\n",
    "subtrain_rmse_list=[]\n",
    "valid_rmse_list=[]\n",
    "\n",
    "z=0.5\n",
    "\n",
    "for epoch_id in range(0, nepoch):\n",
    "    early_stop=False\n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "        #reshape target to two-dimensional array\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        step_count += 1\n",
    "        net.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)        \n",
    "        loss = L2PlusL1Loss(outputs, targets, z)\n",
    "        sse = mse(outputs, targets) * len(inputs)\n",
    "        \n",
    "        subtrain_accumulated_sse += sse\n",
    "        subtrain_accumulated_N += len(inputs)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        earlystop_waiting+=1\n",
    "        if step_count % log_interval == 0:\n",
    "            subtrain_rmse = math.sqrt(subtrain_accumulated_sse / subtrain_accumulated_N)\n",
    "            batch_list.append(step_count)\n",
    "            subtrain_rmse_list.append(subtrain_rmse)\n",
    "            subtrain_accumulated_sse = 0\n",
    "            subtrain_accumulated_N = 0\n",
    "            valid_rmse = calculate_ValidRMSE(net)\n",
    "            valid_rmse_list.append(valid_rmse)\n",
    "            print(\"Epoch %d Step %d Subtrain_RMSE = %.3f Validation_RMSE = %.3f\" % (epoch_id, step_count, subtrain_rmse, valid_rmse))\n",
    "            if(valid_rmse<validation_minrmse):\n",
    "                validation_minrmse=valid_rmse\n",
    "                best_net=copy.deepcopy(net)\n",
    "                best_step_count=step_count\n",
    "                earlystop_waiting=0\n",
    "        if earlystop_waiting>5000:\n",
    "            early_stop=True\n",
    "            break;\n",
    "    if(early_stop):\n",
    "        print(\"Best Step:\", best_step_count)\n",
    "        print(\"Early stop at:\", step_count)\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Q7 Line Chart\n",
    "plt.plot(batch_list,subtrain_rmse_list,label='Subtrain')\n",
    "plt.plot(batch_list,valid_rmse_list,label='Valid')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Batch V.S. RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING RMSE: 9.022216925700386\n"
     ]
    }
   ],
   "source": [
    "test_accumulated_SSE = 0\n",
    "test_accumulated_N = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):            \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        outputs = best_net(inputs)        \n",
    "        cn_loss = mse(outputs, targets) * len(inputs)\n",
    "        test_accumulated_N += len(inputs)\n",
    "        test_accumulated_SSE += cn_loss\n",
    "\n",
    "rmse = math.sqrt(test_accumulated_SSE / test_accumulated_N)\n",
    "print(\"TESTING RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z: 0.0\n",
      "Running on device:  cpu\n",
      "Best Step: 6400\n",
      "Early stop at: 11401\n",
      "TESTING RMSE: 9.281065454157485\n",
      "Z: 0.1\n",
      "Running on device:  cpu\n",
      "Best Step: 15000\n",
      "Early stop at: 20001\n",
      "TESTING RMSE: 9.044107649664003\n",
      "Z: 0.9\n",
      "Running on device:  cpu\n",
      "Best Step: 7400\n",
      "Early stop at: 12401\n",
      "TESTING RMSE: 9.018497954697708\n",
      "Z: 1.0\n",
      "Running on device:  cpu\n",
      "Best Step: 18000\n",
      "Early stop at: 23001\n",
      "TESTING RMSE: 9.025646121072553\n"
     ]
    }
   ],
   "source": [
    "z_list=[0.0, 0.1, 0.9, 1.0]\n",
    "z_tune_outcome_list=[]\n",
    "z_tune_outcome_list.append([0.5,rmse])\n",
    "\n",
    "for i in range(len(z_list)):\n",
    "    \n",
    "    best_net=Q7Train(net,z_list[i],False)\n",
    "    \n",
    "    test_accumulated_SSE = 0\n",
    "    test_accumulated_N = 0\n",
    "\n",
    "    # testing\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            targets = targets.reshape((-1, 1))\n",
    "            outputs = best_net(inputs)        \n",
    "            cn_loss = mse(outputs, targets) * len(inputs)\n",
    "            test_accumulated_N += len(inputs)\n",
    "            test_accumulated_SSE += cn_loss\n",
    "\n",
    "    rmse = math.sqrt(test_accumulated_SSE / test_accumulated_N)\n",
    "    print(\"TESTING RMSE:\", rmse)\n",
    "    z_tune_outcome_list.append([z_list[i],rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Z</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9.022217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.281065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>9.044108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9</td>\n",
       "      <td>9.018498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.025646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Z      RMSE\n",
       "0  0.5  9.022217\n",
       "1  0.0  9.281065\n",
       "2  0.1  9.044108\n",
       "3  0.9  9.018498\n",
       "4  1.0  9.025646"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(z_tune_outcome_list)\n",
    "df=pd.DataFrame(z_tune_outcome_list,columns = ['Z','RMSE'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7解釋：  \n",
    "Training和Validation RMSE的圖如上輸出所示，當z=0.5的時候，可得RMSE約為9.022。  \n",
    "比較 z = 0.0, 0.1, 0.9, 1.0，可知當z=0.9時有最好的RMSE表現，z=0的時候RMSE表現最差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8 L2 + Customerized Loss (15%)\n",
    "考慮另一個比較特別的Loss Function\n",
    "\n",
    "$$\n",
    "qloss(\\mathbf{y}, \\hat{\\mathbf{y}}) = \\sum_{i=1}^n \\{ q (y_i - \\hat{y}_i)_+ + (1 - q) (\\hat{y}_i - y_i)_+ \\},\n",
    "$$\n",
    "其中q為參數且$0<=q<=1$，而$(y_i - \\hat{y}_i)_+$是取正值的意思。也就是說如果$(y_i - \\hat{y}_i) > 0$，則$(y_i - \\hat{y}_i)_+ = y_i - \\hat{y}_i$，否則$(y_i - \\hat{y}_i)_+ = 0$。\n",
    "\n",
    "令模型的Loss為$z \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + (1 - z) \\sum_{i=1}^n \\{ 0.5 (y_i - \\hat{y}_i)_+ + 0.5 (\\hat{y}_i - y_i)_+ \\} $。請使用Q5中的MLP with Dropout模型(H = 90)，令z = 0。並以Adam訓練模型。畫出Training and Validation RMSE，並報告Test RMSE。注意這裡繪圖時應使用RMSE而不是這個特殊的Loss。\n",
    "\n",
    "另外，使用z = 0.1, 0.5, 0.9, 1.0訓練模型(不須提供訓練過程的Loss圖形)，統整各個z值下的Test RMSE並討論。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2PlusCustomerizedLoss(y,yhat,z):\n",
    "    return z*torch.sum((y-yhat)**2)+(1-z)*torch.sum(0.5*torch.clamp(y-yhat,min=0)+0.5*torch.clamp(yhat-y,min=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q8Train(net,z,showsuboutcome):\n",
    "    \n",
    "    net=CreateNetwithDropout(90)\n",
    "    print(\"Z\",z)\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)\n",
    "    mse = torch.nn.MSELoss()\n",
    "\n",
    "    nepoch = 100 \n",
    "    step_count = 0 # batch number\n",
    "    log_interval = 100\n",
    "    subtrain_accumulated_sse = 0\n",
    "    subtrain_accumulated_N = 0\n",
    "\n",
    "    validation_minrmse = 999999\n",
    "    best_net = copy.deepcopy(net)\n",
    "    best_step_count = 0\n",
    "    earlystop_waiting = 0\n",
    "\n",
    "    for epoch_id in range(0, nepoch):\n",
    "        early_stop=False\n",
    "        for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "            #reshape target to two-dimensional array\n",
    "            targets = targets.reshape((-1, 1))\n",
    "            step_count += 1\n",
    "            net.train()\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)        \n",
    "            loss = L2PlusCustomerizedLoss(outputs, targets, z)\n",
    "            sse = mse(outputs, targets) * len(inputs)\n",
    "\n",
    "            subtrain_accumulated_sse += sse\n",
    "            subtrain_accumulated_N += len(inputs)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            earlystop_waiting+=1\n",
    "            \n",
    "            if step_count % log_interval == 0:\n",
    "                subtrain_rmse = math.sqrt(subtrain_accumulated_sse / subtrain_accumulated_N)\n",
    "                batch_list.append(step_count)\n",
    "                subtrain_rmse_list.append(subtrain_rmse)\n",
    "                subtrain_accumulated_sse = 0\n",
    "                subtrain_accumulated_N = 0\n",
    "                valid_rmse = calculate_ValidRMSE(net)\n",
    "                valid_rmse_list.append(valid_rmse)\n",
    "                if showsuboutcome:\n",
    "                    print(\"Epoch %d Step %d Subtrain_RMSE = %.3f Validation_RMSE = %.3f\" % (epoch_id, step_count, subtrain_rmse, valid_rmse))\n",
    "                if(valid_rmse<validation_minrmse):\n",
    "                    validation_minrmse=valid_rmse\n",
    "                    best_net=copy.deepcopy(net)\n",
    "                    best_step_count=step_count\n",
    "                    earlystop_waiting=0\n",
    "            if earlystop_waiting>5000:\n",
    "                early_stop=True\n",
    "                break;\n",
    "        if(early_stop):\n",
    "            print(\"Best Step:\", best_step_count)\n",
    "            print(\"Early stop at:\", step_count)\n",
    "            break;\n",
    "            \n",
    "    return best_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device:  cpu\n",
      "Epoch 0 Step 100 Subtrain_RMSE = 11.013 Validation_RMSE = 10.690\n",
      "Epoch 0 Step 200 Subtrain_RMSE = 10.473 Validation_RMSE = 9.978\n",
      "Epoch 0 Step 300 Subtrain_RMSE = 9.841 Validation_RMSE = 9.759\n",
      "Epoch 0 Step 400 Subtrain_RMSE = 9.698 Validation_RMSE = 9.596\n",
      "Epoch 1 Step 500 Subtrain_RMSE = 9.599 Validation_RMSE = 9.505\n",
      "Epoch 1 Step 600 Subtrain_RMSE = 9.544 Validation_RMSE = 9.498\n",
      "Epoch 1 Step 700 Subtrain_RMSE = 9.484 Validation_RMSE = 9.476\n",
      "Epoch 1 Step 800 Subtrain_RMSE = 9.493 Validation_RMSE = 9.446\n",
      "Epoch 2 Step 900 Subtrain_RMSE = 9.409 Validation_RMSE = 9.381\n",
      "Epoch 2 Step 1000 Subtrain_RMSE = 9.398 Validation_RMSE = 9.417\n",
      "Epoch 2 Step 1100 Subtrain_RMSE = 9.465 Validation_RMSE = 9.336\n",
      "Epoch 2 Step 1200 Subtrain_RMSE = 9.372 Validation_RMSE = 9.350\n",
      "Epoch 3 Step 1300 Subtrain_RMSE = 9.461 Validation_RMSE = 9.413\n",
      "Epoch 3 Step 1400 Subtrain_RMSE = 9.431 Validation_RMSE = 9.342\n",
      "Epoch 3 Step 1500 Subtrain_RMSE = 9.328 Validation_RMSE = 9.363\n",
      "Epoch 3 Step 1600 Subtrain_RMSE = 9.431 Validation_RMSE = 9.299\n",
      "Epoch 4 Step 1700 Subtrain_RMSE = 9.331 Validation_RMSE = 9.346\n",
      "Epoch 4 Step 1800 Subtrain_RMSE = 9.268 Validation_RMSE = 9.329\n",
      "Epoch 4 Step 1900 Subtrain_RMSE = 9.328 Validation_RMSE = 9.302\n",
      "Epoch 4 Step 2000 Subtrain_RMSE = 9.393 Validation_RMSE = 9.234\n",
      "Epoch 5 Step 2100 Subtrain_RMSE = 9.419 Validation_RMSE = 9.314\n",
      "Epoch 5 Step 2200 Subtrain_RMSE = 9.364 Validation_RMSE = 9.314\n",
      "Epoch 5 Step 2300 Subtrain_RMSE = 9.267 Validation_RMSE = 9.269\n",
      "Epoch 5 Step 2400 Subtrain_RMSE = 9.344 Validation_RMSE = 9.257\n",
      "Epoch 5 Step 2500 Subtrain_RMSE = 9.299 Validation_RMSE = 9.264\n",
      "Epoch 6 Step 2600 Subtrain_RMSE = 9.305 Validation_RMSE = 9.248\n",
      "Epoch 6 Step 2700 Subtrain_RMSE = 9.351 Validation_RMSE = 9.260\n",
      "Epoch 6 Step 2800 Subtrain_RMSE = 9.265 Validation_RMSE = 9.280\n",
      "Epoch 6 Step 2900 Subtrain_RMSE = 9.289 Validation_RMSE = 9.263\n",
      "Epoch 7 Step 3000 Subtrain_RMSE = 9.305 Validation_RMSE = 9.262\n",
      "Epoch 7 Step 3100 Subtrain_RMSE = 9.278 Validation_RMSE = 9.265\n",
      "Epoch 7 Step 3200 Subtrain_RMSE = 9.313 Validation_RMSE = 9.290\n",
      "Epoch 7 Step 3300 Subtrain_RMSE = 9.266 Validation_RMSE = 9.261\n",
      "Epoch 8 Step 3400 Subtrain_RMSE = 9.215 Validation_RMSE = 9.222\n",
      "Epoch 8 Step 3500 Subtrain_RMSE = 9.244 Validation_RMSE = 9.253\n",
      "Epoch 8 Step 3600 Subtrain_RMSE = 9.321 Validation_RMSE = 9.264\n",
      "Epoch 8 Step 3700 Subtrain_RMSE = 9.254 Validation_RMSE = 9.276\n",
      "Epoch 9 Step 3800 Subtrain_RMSE = 9.309 Validation_RMSE = 9.229\n",
      "Epoch 9 Step 3900 Subtrain_RMSE = 9.261 Validation_RMSE = 9.187\n",
      "Epoch 9 Step 4000 Subtrain_RMSE = 9.265 Validation_RMSE = 9.206\n",
      "Epoch 9 Step 4100 Subtrain_RMSE = 9.255 Validation_RMSE = 9.213\n",
      "Epoch 10 Step 4200 Subtrain_RMSE = 9.254 Validation_RMSE = 9.201\n",
      "Epoch 10 Step 4300 Subtrain_RMSE = 9.257 Validation_RMSE = 9.235\n",
      "Epoch 10 Step 4400 Subtrain_RMSE = 9.227 Validation_RMSE = 9.226\n",
      "Epoch 10 Step 4500 Subtrain_RMSE = 9.253 Validation_RMSE = 9.237\n",
      "Epoch 11 Step 4600 Subtrain_RMSE = 9.234 Validation_RMSE = 9.217\n",
      "Epoch 11 Step 4700 Subtrain_RMSE = 9.244 Validation_RMSE = 9.227\n",
      "Epoch 11 Step 4800 Subtrain_RMSE = 9.245 Validation_RMSE = 9.221\n",
      "Epoch 11 Step 4900 Subtrain_RMSE = 9.216 Validation_RMSE = 9.220\n",
      "Epoch 11 Step 5000 Subtrain_RMSE = 9.286 Validation_RMSE = 9.154\n",
      "Epoch 12 Step 5100 Subtrain_RMSE = 9.187 Validation_RMSE = 9.176\n",
      "Epoch 12 Step 5200 Subtrain_RMSE = 9.211 Validation_RMSE = 9.208\n",
      "Epoch 12 Step 5300 Subtrain_RMSE = 9.279 Validation_RMSE = 9.172\n",
      "Epoch 12 Step 5400 Subtrain_RMSE = 9.222 Validation_RMSE = 9.196\n",
      "Epoch 13 Step 5500 Subtrain_RMSE = 9.174 Validation_RMSE = 9.226\n",
      "Epoch 13 Step 5600 Subtrain_RMSE = 9.307 Validation_RMSE = 9.179\n",
      "Epoch 13 Step 5700 Subtrain_RMSE = 9.198 Validation_RMSE = 9.216\n",
      "Epoch 13 Step 5800 Subtrain_RMSE = 9.205 Validation_RMSE = 9.205\n",
      "Epoch 14 Step 5900 Subtrain_RMSE = 9.243 Validation_RMSE = 9.212\n",
      "Epoch 14 Step 6000 Subtrain_RMSE = 9.276 Validation_RMSE = 9.181\n",
      "Epoch 14 Step 6100 Subtrain_RMSE = 9.138 Validation_RMSE = 9.220\n",
      "Epoch 14 Step 6200 Subtrain_RMSE = 9.242 Validation_RMSE = 9.205\n",
      "Epoch 15 Step 6300 Subtrain_RMSE = 9.244 Validation_RMSE = 9.222\n",
      "Epoch 15 Step 6400 Subtrain_RMSE = 9.183 Validation_RMSE = 9.217\n",
      "Epoch 15 Step 6500 Subtrain_RMSE = 9.125 Validation_RMSE = 9.204\n",
      "Epoch 15 Step 6600 Subtrain_RMSE = 9.290 Validation_RMSE = 9.203\n",
      "Epoch 16 Step 6700 Subtrain_RMSE = 9.331 Validation_RMSE = 9.177\n",
      "Epoch 16 Step 6800 Subtrain_RMSE = 9.160 Validation_RMSE = 9.152\n",
      "Epoch 16 Step 6900 Subtrain_RMSE = 9.170 Validation_RMSE = 9.224\n",
      "Epoch 16 Step 7000 Subtrain_RMSE = 9.237 Validation_RMSE = 9.238\n",
      "Epoch 16 Step 7100 Subtrain_RMSE = 9.240 Validation_RMSE = 9.256\n",
      "Epoch 17 Step 7200 Subtrain_RMSE = 9.233 Validation_RMSE = 9.263\n",
      "Epoch 17 Step 7300 Subtrain_RMSE = 9.227 Validation_RMSE = 9.210\n",
      "Epoch 17 Step 7400 Subtrain_RMSE = 9.185 Validation_RMSE = 9.223\n",
      "Epoch 17 Step 7500 Subtrain_RMSE = 9.235 Validation_RMSE = 9.194\n",
      "Epoch 18 Step 7600 Subtrain_RMSE = 9.079 Validation_RMSE = 9.158\n",
      "Epoch 18 Step 7700 Subtrain_RMSE = 9.231 Validation_RMSE = 9.205\n",
      "Epoch 18 Step 7800 Subtrain_RMSE = 9.268 Validation_RMSE = 9.250\n",
      "Epoch 18 Step 7900 Subtrain_RMSE = 9.256 Validation_RMSE = 9.185\n",
      "Epoch 19 Step 8000 Subtrain_RMSE = 9.193 Validation_RMSE = 9.198\n",
      "Epoch 19 Step 8100 Subtrain_RMSE = 9.209 Validation_RMSE = 9.182\n",
      "Epoch 19 Step 8200 Subtrain_RMSE = 9.177 Validation_RMSE = 9.196\n",
      "Epoch 19 Step 8300 Subtrain_RMSE = 9.193 Validation_RMSE = 9.177\n",
      "Epoch 20 Step 8400 Subtrain_RMSE = 9.223 Validation_RMSE = 9.206\n",
      "Epoch 20 Step 8500 Subtrain_RMSE = 9.224 Validation_RMSE = 9.211\n",
      "Epoch 20 Step 8600 Subtrain_RMSE = 9.273 Validation_RMSE = 9.188\n",
      "Epoch 20 Step 8700 Subtrain_RMSE = 9.136 Validation_RMSE = 9.163\n",
      "Epoch 21 Step 8800 Subtrain_RMSE = 9.180 Validation_RMSE = 9.157\n",
      "Epoch 21 Step 8900 Subtrain_RMSE = 9.250 Validation_RMSE = 9.196\n",
      "Epoch 21 Step 9000 Subtrain_RMSE = 9.172 Validation_RMSE = 9.190\n",
      "Epoch 21 Step 9100 Subtrain_RMSE = 9.161 Validation_RMSE = 9.209\n",
      "Epoch 22 Step 9200 Subtrain_RMSE = 9.199 Validation_RMSE = 9.179\n",
      "Epoch 22 Step 9300 Subtrain_RMSE = 9.253 Validation_RMSE = 9.191\n",
      "Epoch 22 Step 9400 Subtrain_RMSE = 9.163 Validation_RMSE = 9.242\n",
      "Epoch 22 Step 9500 Subtrain_RMSE = 9.123 Validation_RMSE = 9.179\n",
      "Epoch 22 Step 9600 Subtrain_RMSE = 9.242 Validation_RMSE = 9.200\n",
      "Epoch 23 Step 9700 Subtrain_RMSE = 9.214 Validation_RMSE = 9.210\n",
      "Epoch 23 Step 9800 Subtrain_RMSE = 9.230 Validation_RMSE = 9.177\n",
      "Epoch 23 Step 9900 Subtrain_RMSE = 9.147 Validation_RMSE = 9.236\n",
      "Epoch 23 Step 10000 Subtrain_RMSE = 9.215 Validation_RMSE = 9.227\n",
      "Epoch 24 Step 10100 Subtrain_RMSE = 9.242 Validation_RMSE = 9.197\n",
      "Epoch 24 Step 10200 Subtrain_RMSE = 9.209 Validation_RMSE = 9.206\n",
      "Epoch 24 Step 10300 Subtrain_RMSE = 9.173 Validation_RMSE = 9.168\n",
      "Epoch 24 Step 10400 Subtrain_RMSE = 9.163 Validation_RMSE = 9.213\n",
      "Epoch 25 Step 10500 Subtrain_RMSE = 9.202 Validation_RMSE = 9.185\n",
      "Epoch 25 Step 10600 Subtrain_RMSE = 9.200 Validation_RMSE = 9.190\n",
      "Epoch 25 Step 10700 Subtrain_RMSE = 9.212 Validation_RMSE = 9.248\n",
      "Epoch 25 Step 10800 Subtrain_RMSE = 9.183 Validation_RMSE = 9.206\n",
      "Epoch 26 Step 10900 Subtrain_RMSE = 9.146 Validation_RMSE = 9.174\n",
      "Epoch 26 Step 11000 Subtrain_RMSE = 9.183 Validation_RMSE = 9.192\n",
      "Epoch 26 Step 11100 Subtrain_RMSE = 9.229 Validation_RMSE = 9.175\n",
      "Epoch 26 Step 11200 Subtrain_RMSE = 9.213 Validation_RMSE = 9.171\n",
      "Epoch 27 Step 11300 Subtrain_RMSE = 9.159 Validation_RMSE = 9.166\n",
      "Epoch 27 Step 11400 Subtrain_RMSE = 9.149 Validation_RMSE = 9.184\n",
      "Epoch 27 Step 11500 Subtrain_RMSE = 9.180 Validation_RMSE = 9.188\n",
      "Epoch 27 Step 11600 Subtrain_RMSE = 9.191 Validation_RMSE = 9.199\n",
      "Epoch 27 Step 11700 Subtrain_RMSE = 9.216 Validation_RMSE = 9.164\n",
      "Epoch 28 Step 11800 Subtrain_RMSE = 9.185 Validation_RMSE = 9.181\n",
      "Best Step: 6800\n",
      "Early stop at: 11801\n"
     ]
    }
   ],
   "source": [
    "net=CreateNetwithDropout(90)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)\n",
    "mse = torch.nn.MSELoss()\n",
    "\n",
    "nepoch = 100 \n",
    "step_count = 0 # batch number\n",
    "log_interval = 100\n",
    "subtrain_accumulated_sse = 0\n",
    "subtrain_accumulated_N = 0\n",
    "\n",
    "validation_minrmse = 999999\n",
    "best_net = copy.deepcopy(net)\n",
    "best_step_count = 0\n",
    "earlystop_waiting = 0\n",
    "\n",
    "batch_list=[]\n",
    "subtrain_rmse_list=[]\n",
    "valid_rmse_list=[]\n",
    "\n",
    "z=0\n",
    "\n",
    "for epoch_id in range(0, nepoch):\n",
    "    early_stop=False\n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "        #reshape target to two-dimensional array\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        step_count += 1\n",
    "        net.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)        \n",
    "        loss = L2PlusCustomerizedLoss(outputs, targets, z)\n",
    "        sse = mse(outputs, targets) * len(inputs)\n",
    "        \n",
    "        subtrain_accumulated_sse += sse\n",
    "        subtrain_accumulated_N += len(inputs)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        earlystop_waiting+=1\n",
    "        if step_count % log_interval == 0:\n",
    "            subtrain_rmse = math.sqrt(subtrain_accumulated_sse / subtrain_accumulated_N)\n",
    "            batch_list.append(step_count)\n",
    "            subtrain_rmse_list.append(subtrain_rmse)\n",
    "            subtrain_accumulated_sse = 0\n",
    "            subtrain_accumulated_N = 0\n",
    "            valid_rmse = calculate_ValidRMSE(net)\n",
    "            valid_rmse_list.append(valid_rmse)\n",
    "            print(\"Epoch %d Step %d Subtrain_RMSE = %.3f Validation_RMSE = %.3f\" % (epoch_id, step_count, subtrain_rmse, valid_rmse))\n",
    "            if(valid_rmse<validation_minrmse):\n",
    "                validation_minrmse=valid_rmse\n",
    "                best_net=copy.deepcopy(net)\n",
    "                best_step_count=step_count\n",
    "                earlystop_waiting=0\n",
    "        if earlystop_waiting>5000:\n",
    "            early_stop=True\n",
    "            break;\n",
    "    if(early_stop):\n",
    "        print(\"Best Step:\", best_step_count)\n",
    "        print(\"Early stop at:\", step_count)\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdd3hVVfbw8e9K7k0nAZLQS2gKCEiJICKICNhQEFHErtj76+jozOiM44xlZpzRn46jYgMVwY6KAmIBlR5a6D1AIJBCS0jPXe8f5ySEcJNQ0oT1eZ773HPP2eecfSNmZe29z96iqhhjjDEnKqC2K2CMMebkYAHFGGNMlbCAYowxpkpYQDHGGFMlLKAYY4ypEhZQjDHGVAkLKMYcJRFJEpHBtV0PY+oqCyjmN839JZ8jIlkisldEvhGRlkd5bpyIqIh4qrhOfUXkoIjU83NsqYjc52d/sIi8JCI7RCRTRLaIyAtHeb/BIuJzfwaZIrJWRG4sddzjfs+dIhJYan+QiGSISGGpfV1FZKb7s9wrIgkicqGf+5R+nXWsPyNzcrKAYk4Gl6lqBNAU2A28UpuVUdV5QDJwZen9ItIF6AxM8nPaE0A3oBcQCQwClh3Dbbe5P4NI4FHgHRFpX6ZMJjC01OdhQHqp+gkwFfgWaAQ0Af4fkFX2PmVei46hnuYkZgHFnDRUNRf4FOeXNgAicqmbFRwQke0i8lSpU3523/e5f2n3dc+5XUTWuH/trxaRnqXO6S4iiSKyX0Q+EpGQcqozAbixzL4bgW9UNcNP+bOAz1V1lzq2qOoHR//tHe65XwMHgK5lDr9fpk43Au+V+twYaAW8qaoFqpqnqr+o6pxjrYc5NVlAMScNEQkDRgPzS+0+iPOLsz5wKXC3iIxwjw1w3+u7f2nPE5GrgKfccyKBy4HSAeBq4CKgDU5GcXM51Xkf6C8irdy6BQDXcvgv8NLmA4+KyN0i0sXNFo6ZiASIyBVAA2BjmcOfA4NEJFJEooGzcTKSYqnAZmCiiAwXkUbHUwdz6rKAYk4GU0RkH85f5UOAfxUfUNVZqrpCVX2qmojT3HReBde6Dfinqi5y/9rfqKpbSx1/WVV3quoe4Gugu7+LqOp2YDZwvbvrAiAE+Kac+/4deAG4AVgMJIvI9eWU9aeV+zPIwcnS7lfVFWXKZAPTgKuAMcAXQF6pOvuAgcAO4EUgRUR+EpF2Ze9T5hV8DPU0JzELKOZkMEJV6wPBwH3AbBFpAiAifdxfimkish+4C4ip4FotgU0VHN9VajsbiKigbOlmrxuAD1W1wF9BVS1U1VdU9RycbOqfwHgROa2C65e2zf0ZRAKv4gQwf95z61S2uau4HttV9R5VbYuThRUA48vep8wrr+x1zKnJAoo5aahqkap+DhQB57q7PwS+AlqqahTwOlDcnORvqu3tQDs/+4/H50BzETkfGEn5zV2HUdUcVf0/nM7wTsdyQ/eX+6NATxEZ5qfIT0BrnGa+eZVcaxvwP6DLsdTBnLosoJiThjiG4/QfrHF31wP2qGquiPTG6ccolgb4gLal9r0FPCIivdzrtReR1sdTH1U9iNP89C6wVVUTKqj7/xORASIS6g7zvRWniexYRnoV3zcPp8nqz36OKc7orhFlj4lIjIj8RUTaut89FriFw/ukjCmXBRRzMvhaRLJw+lCeAW5S1VXusXuAp0UkE+cX7MfFJ6lqtlt+jtsXcLaqfuLu+xBnmO0UoOEJ1G0CTkZwWHYiIoGlR5YBucBLOMOe04E7gZHF/Tci8p2I/P4Y7vsW0F5ELi57QFVXqupqP+fk4WRnP+FkRyvc91tLlWnl5zmUI4KTOTWJLbBljDGmKliGYowxpkpYQDHGGFMlLKAYY4ypEhZQjDHGVIkqnWW1roqJidG4uLjaroYxxvymLF68OF1VY4+2/CkRUOLi4khIKPcRAGOMMX6IyNbKSx1iTV7GGGOqhAUUY4wxVcICijHGmCpxSvShGGNODQUFBSQnJ5Obm1vbVflNCQkJoUWLFni93hO6jgUUY8xJIzk5mXr16hEXF8dxrlF2ylFVMjIySE5Opk2bNid0LWvyMsacNHJzc4mOjrZgcgxEhOjo6CrJ6qotoIjIOyKSKiIrS+27SkRWiYhPROIrOPciEVknIhtF5PFS+9uIyAIR2eCu5x1UXfU3xvw2WTA5dlX1M6vODGU8ztrbpa3EWWjo5/JOEpFAnBXnLgY6A2NEpLN7+B/Ai6raAdgLjK3iOh/mi6XJTFxwTMOwjTHmlFVtAUVVfwb2lNm3RlXXVXJqb2Cjqm5W1XxgMjBcnBA6CGfBInDWmajWdRimLk/hwwXbqvMWxpiT0DPPPMMZZ5xBt27d6N69OwsWLCi37FNPPcULL7xwxP6kpCQ+/PDD47r/Oeecc1znnai62CnfHGcZ1mLJQB8gGtinqoWl9jevzoqEBXvIzi+qzlsYY04y8+bNY+rUqSxZsoTg4GDS09PJz88/5usUB5Rrr732iGOFhYV4POX/+p47d+4x368q1MVOeX+NeVrBfv8XEblDRBJEJCEtLe24KhIeFMjBvMLKCxpjjCslJYWYmBiCg4MBiImJoVmzZsTFxZGeng5AQkICAwcOLDln+fLlDBo0iA4dOvDmm28C8Pjjj/PLL7/QvXt3XnzxRcaPH89VV13FZZddxtChQ8nKyuKCCy6gZ8+edO3alS+//LLkehEREQDMmjWLgQMHMmrUKDp27Mh1111HdS6qWBczlGSgZanPLYCdOMui1hcRj5ulFO/3S1XHAeMA4uPjj+snGBZkGYoxv1V//XoVq3ceqNJrdm4WyV8uO6PCMkOHDuXpp5/mtNNOY/DgwYwePZrzzjuvwnMSExOZP38+Bw8epEePHlx66aU8//zzvPDCC0ydOhWA8ePHM2/ePBITE2nYsCGFhYV88cUXREZGkp6eztlnn83ll19+RAf70qVLWbVqFc2aNaNfv37MmTOHc88998R+EOWoixnKIqCDO6IrCLgG+EqdsPoTMMotdxPwZTnXqBLhwYEczC+s1ohujDm5REREsHjxYsaNG0dsbCyjR49m/PjxFZ4zfPhwQkNDiYmJ4fzzz2fhwoV+yw0ZMoSGDRsCzvMjf/zjH+nWrRuDBw9mx44d7N69+4hzevfuTYsWLQgICKB79+4kJSWd6FcsV7VlKCIyCRgIxIhIMvAXnE76V4BY4BsRWaaqF4pIM+AtVb1EVQtF5D5gBhAIvKOqq9zLPgZMFpG/A0uBt6ur/gDhwR5UIbfAR2hQYHXeyhhTxSrLJKpTYGAgAwcOZODAgXTt2pUJEybg8Xjw+XwARzzzUTarKG8Yb3h4eMn2xIkTSUtLY/HixXi9XuLi4vw+S1Lc9FZcr8LC6mvGr85RXmNUtamqelW1haq+rapfuNvBqtpYVS90y+5U1UtKnfutqp6mqu1U9ZlS+zeram9Vba+qV6lqXnXVH5w+FICD+daPYow5OuvWrWPDhg0ln5ctW0br1q2Ji4tj8eLFAHz22WeHnfPll1+Sm5tLRkYGs2bN4qyzzqJevXpkZmaWe5/9+/fTqFEjvF4vP/30E1u31v4jDnWxD6XOCAtyfjwH8wqJiQiupLQxxkBWVhb3338/+/btw+Px0L59e8aNG8eaNWsYO3Yszz77LH369DnsnN69e3PppZeybds2nnzySZo1a0ZsbCwej4czzzyTm2++mQYNGhx2znXXXcdll11GfHw83bt3p2PHjjX5Nf2SU6F/ID4+Xo9nga3pK1O464MlfPtAfzo3i6yGmhljqtKaNWvo1KlTbVfjN8nfz05EFqtqubOalFUXO+XrjOIMJduavIwxplIWUCoQHlzch2JDh40xpjIWUCpQkqHYw43GGFMpCygVCC/ulLcMxRhjKmUBpQJhbpOX9aEYY0zlLKBUoCRDybMMxRhjKmMBpQIh3gBELEMxxhydgQMHMmPGjMP2vfTSS9xzzz3lnlM8kePOnTsZNWqU3zIDBw7keB59qGkWUCogIoQHeSxDMcYclTFjxjB58uTD9k2ePJkxY8ZUem6zZs349NNPKy1Xl1lAqURYUKBlKMaYozJq1CimTp1KXp4zK1RSUhI7d+6ke/fu5U41XywpKYkuXboAkJOTwzXXXEO3bt0YPXo0OTk5Nfo9jpdNvVKJ8GCPjfIy5rdo2uOwa0XVXrNJV7j4+XIPR0dH07t3b6ZPn87w4cOZPHkyo0ePJjQ09Kimmi/22muvERYWRmJiIomJifTs2bNqv0c1sQylEmFBgfYcijHmqJVu9ipu7jraqeaL/fzzz1x//fUAdOvWjW7dutVI3U+UZSiVcDIUCyjG/OZUkElUpxEjRvDwww+zZMkScnJy6NmzJ+PHjz+qqeZLKy97qcssQ6lEeFCgrdpojDlqERERDBw4kFtvvbWkM/5Yp5ofMGAAEydOBGDlypUkJiZWe72rggWUSoQFe8iyJi9jzDEYM2YMy5cv55prrgGcqeYTEhKIj49n4sSJlU41f/fdd5OVlUW3bt345z//Se/evWui2ifMmrwqER4USLYNGzbGHIMrrrjisKXDY2JimDdvnt+yWVlZAMTFxbFy5UoAQkNDjxh+/FtQbRmKiLwjIqkisrLUvoYiMlNENrjvDfycd76ILCv1yhWREe6x8SKypdSx7tVV/2JhQdaHYowxR6M6m7zGAxeV2fc48IOqdgB+cD8fRlV/UtXuqtodGARkA9+VKvJo8XFVXVY9VT8kPNjpQzkVFiIzxpgTUZ1ryv8M7Cmzezgwwd2eAIyo5DKjgGmqml3F1TtqYUEeinxKXqGvtqpgjDkG9sffsauqn1lNd8o3VtUUAPe9USXlrwEmldn3jIgkisiLIlLuQu8icoeIJIhIQlpa2nFXODyoeMZh60cxpq4LCQkhIyPDgsoxUFUyMjIICQk54WvV2U55EWkKdAVKz7T2B2AXEASMAx4DnvZ3vqqOc8sQHx9/3P+6woKLZxwupGF40PFexhhTA1q0aEFycjIn8kfkqSgkJIQWLVqc8HVqOqDsFpGmqpriBozUCspeDXyhqgXFO4qzGyBPRN4FHqnGugKHprC3DMWYus/r9dKmTZvarsYpq6abvL4CbnK3bwKOnCHtkDGUae5ygxDiPEI6Aljp57wqFVayrryN9DLGmIpU57DhScA84HQRSRaRscDzwBAR2QAMcT8jIvEi8lapc+OAlsDsMpedKCIrgBVADPD36qp/sZIMxZ5FMcaYClVbk5eqlrcAwAV+yiYAt5X6nAQ091NuUFXV76is+oJmqRlAU8tQjDGmEjb1SkWWTSJ29XjAVm00xpjKWECpiDeEwCJnoRxbtdEYYypmAaUinlACipwppi1DMcaYillAqYg3BCl0lt7MsgzFGGMqZAGlIp5QpCDXVm00xpijYAGlIt4QKMxxZxy2DMUYYypiAaUi3jDwFRIZZH0oxhhTGQsoFfE4k6XVDyqyUV7GGFMJCygV8YYCUN9bZBmKMcZUwgJKRdwMJcpbZH0oxhhTCQsoFSnOUDwFNsrLGGMqYQGlIm6GUi+w0KavN8aYSlhAqYjXCSiRnkKbHNIYYyphAaUi3jAAwgMLbfp6Y4yphAWUirhNXhEBBeQX+cgv9NVyhYwxpu6ygFIRt1M+PNBZhTjH+lGMMaZcFlAq4mYo4ZIP2DLAxhhTkepcAvgdEUkVkZWl9jUUkZkissF9b1DOuUUissx9fVVqfxsRWeCe/5GIBFVX/YGSDCVUnAzFHm40xpjyVWeGMh64qMy+x4EfVLUD8IP72Z8cVe3uvi4vtf8fwIvu+XuBsVVc58O5GUqom6HYFPbGGFO+agsoqvozsKfM7uHABHd7AjDiaK8nIgIMAj49nvOPizvKKxg3Q7GHG40xplw13YfSWFVTANz3RuWUCxGRBBGZLyLFQSMa2Keqxb/Vk4Hm5d1IRO5wr5GQlpZ2fLUN9IIEEEJxH4plKMYYUx5PbVegHK1UdaeItAV+FJEVwAE/5bS8C6jqOGAcQHx8fLnlKiQCnlCC1FlX3vpQjDGmfDWdoewWkaYA7nuqv0KqutN93wzMAnoA6UB9ESkOgi2AndVdYbwheNVZV96msDfGmPLVdED5CrjJ3b4J+LJsARFpICLB7nYM0A9YraoK/ASMquj8KucJxetzmrxyCiygGGNMeapz2PAkYB5wuogki8hY4HlgiIhsAIa4nxGReBF5yz21E5AgIstxAsjzqrraPfYY8LCIbMTpU3m7uupfwhtCoM/JUHItoBhjTLmqrQ9FVceUc+gCP2UTgNvc7blA13KuuRnoXVV1PCqeUAIKcwkMEOtDMcaYCtiT8pXxhiKFuYR6A8nJt7m8jDGmPBZQKuMNgYJcQryB1odijDEVsIBSGU8oFOYQFhRIjjV5GWNMuSygVMYbAgU5TpOXZSjGGFMuCyiV8YQ6TV5BgeQUWB+KMcaUxwJKZbwhTpOXN5Bcm3rFGGPKZQGlMt4wKMglNCiQ7ALrQzHGmPJYQKmMx8lQnGHDlqEYY0x5LKBUxhsKvkLCPEqu9aEYY0y5LKBUxl1kK8pTaE/KG2NMBSygVMZdBriep8CGDRtjTAUsoFTGzVDCAwrJLfDh8x3f0irGGHOys4BSGTdDiQh0lgHOLbQsxRhj/LGAUhk3oIQHOP0nNtLLGGP8s4BSGbfJK0xskS1jjKmIBZTKuBlKWIATUGyRLWOM8a86V2x8R0RSRWRlqX0NRWSmiGxw3xv4Oa+7iMwTkVUikigio0sdGy8iW0RkmfvqXl31L+FmKKE4fSjZ1uRljDF+VWeGMh64qMy+x4EfVLUD8IP7uaxs4EZVPcM9/yURqV/q+KOq2t19LauGeh/OzVBCi5u8LKAYY4xf1RZQVPVnYE+Z3cOBCe72BGCEn/PWq+oGd3snkArEVlc9K+VmKMHWh2KMMRWq6T6UxqqaAuC+N6qosIj0BoKATaV2P+M2hb0oIsEVnHuHiCSISEJaWtrx19jNUILVMhRjjKlIne2UF5GmwPvALapaPInWH4COwFlAQ+Cx8s5X1XGqGq+q8bGxJ5DglA0olqEYY4xfNR1QdruBojhgpPorJCKRwDfAE6o6v3i/qqaoIw94F+hd7TX2OAEliDzAAooxxpSnpgPKV8BN7vZNwJdlC4hIEPAF8J6qflLmWHEwEpz+l5Vlz69ygV6QALw+N6BYk5cxxvhVncOGJwHzgNNFJFlExgLPA0NEZAMwxP2MiMSLyFvuqVcDA4Cb/QwPnigiK4AVQAzw9+qqf6kvAp5QPBZQjDGmQp7qurCqjinn0AV+yiYAt7nbHwAflHPNQVVWwWPhDSGwKBdPgFiTlzHGlKPOdsrXKZ7QQ8sAW4ZijDF+WUA5Gt7QkmWAbeoVY4zxzwLK0fCGlGQo1uRljDH+WUA5Gp5QKMgm1BtonfLGGFOOCgOKiAwqtd2mzLGR1VWpOscbAoWWoRhjTEUqy1BeKLX9WZljT1RxXeouTygU5FiGYowxFagsoEg52/4+n7zcDCXMMhRjjClXZQFFy9n29/nk5Q4bDrEMxRhjylXZg41tReQrnGykeBv3c5vyTzvJlBo2bBmKMcb4V1lAGV5q+4Uyx8p+Pnl5nT4Ua/IyxpjyVRhQVHV26c8i4gW6ADtU1e9MwSclTwgU5BBiT8obY0y5Khs2/LqInOFuRwHLgfeApSJS3lxdJx9vKGgR4YFKfqGPIt+p031kjDFHq7JO+f6qusrdvgVYr6pdgV7A76u1ZnWJuwxwRGABgE2/YowxflQWUPJLbQ8BpgCo6q5qq1Fd5K7aWC+wELBFtowxxp/KAso+ERkmIj2AfsB0ABHxAKHVXbk6w81QwgKcDMWGDhtjzJEqG+V1J/Ay0AR4qFRmcgHOEr2nBjdDCS8OKJahGGPMESob5bUeuMjP/hnAjOqqVJ1TElCcFkDLUIwx5kgVBhQRebmi46r6QCXnvwMMA1JVtYu7ryHwERAHJAFXq+peP+fexKH5wv6uqhPc/b2A8ThNbt8CD6pq9Q67cpu8QsTJUGzosDHGHKmyPpS7gHOBnUACsLjMqzLjOTLDeRz4QVU7AD+4nw/jBp2/AH2A3sBfRKSBe/g14A6gg/s6IoOqcm6GEuqOUbBRXsYYc6TKAkpTYBxwIXAD4AW+UtUJxRlDRVT1Z2BPmd3DgeJzJwAj/Jx6ITBTVfe42ctM4CIRaQpEquo8Nyt5r5zzq1aZDMX6UIwx5kgVBhRVzVDV11X1fOBmoD6wSkRuOIF7NlbVFPf6KUAjP2WaA9tLfU529zV3t8vuP4KI3CEiCSKSkJaWdgLVpSRDCVEnQ7EmL2OMOdJRrdgoIj2Bh4DrgWkcXXPXifA3Nb5WsP/InarjVDVeVeNjY2NPrDZuQAkiF7AMxRhj/Kls6pW/ishi4GFgNhCvqmNVdfUJ3HO323SF++5vTrBkoGWpzy1w+nGS3e2y+6tXSH0Aggv2A5BrGYoxxhyhsgzlSSAKOBN4DlgiIokiskJEEo/znl8BN7nbNwFf+ikzAxgqIg3czvihwAy3iSxTRM4WEQFuLOf8qhUSBUH18GY5scsyFGOMOVJlDzae0JonIjIJGAjEiEgyzsit54GPRWQssA24yi0bD9ylqrep6h4R+RuwyL3U06pa3Ll/N4eGDU9zX9VLBKJaEHBgB0GBAdaHYowxflT2YONWf/tFJBC4BvB7vNT55c1IfIGfsgnAbaU+vwO8U065LhXdt1pENYf92wkNCrRhw8YY40dlfSiRIvIHEfmviAwVx/3AZuDqmqliHRHVAvYnO6s2WoZijDFHqKzJ631gLzAPJ3t4FAgChqvqsmquW90S1QKyM4gKLyTbMhRjjDlCpWvKu+ufICJvAelAK1XNrPaa1TVRzqCzloF7ycmPruXKGGNM3VPZKK+C4g1VLQK2nJLBBCDSeX6yZUCG9aEYY4wflWUoZ4rIAXdbgFD3swCqqpHVWru6JMp5/KWpZLA8v7CWK2OMMXVPZaO8AmuqInVeZDNAaKzp5BT4ars2xhhT51SWoZhinmCIaEwjTSO30Jq8jDGmrKOay8u4opoTXZhmw4aNMcYPCyjHIqoFDQt3k219KMYYcwQLKMciqiVRBbvJKbCAYowxZVlAORZRLfD68ggvyiQtM6+2a2OMMXWKBZRj4T6L0lwyWLvrQCWFjTHm1GIB5Vi4z6I0k3TW7To1n+80xpjyWEA5Fu70K6eF7GetBRRjjDmMBZRjER4DgcF0Dj9gTV7GGFOGBZRjIQJRzYnz7mXD7iwKi+yJeWOMKVYrAUVEHhSRlSKySkQe8nP8URFZ5r5WikiRiDR0jyW5SxAvE5GEGq98VAuaaDp5hT6SMrJr/PbGGFNX1XhAEZEuwO1Ab5y16oeJSIfSZVT1X6raXVW7A38AZpdaAhjgfPd4fI1VvFhUSyLzdwNYx7wxxpRSGxlKJ2C+qmaraiEwG7iigvJjgEk1UrOjEdUST/ZuQgMKrR/FGGNKqY2AshIYICLRIhIGXAK09FfQPX4R8Fmp3Qp8JyKLReSO8m4iIneISIKIJKSlpVVd7aPbI+qjb30b6WWMMaXVeEBR1TXAP4CZwHRgOVDeXCaXAXPKNHf1U9WewMXAvSIyoJz7jFPVeFWNj42NrbovEOO0zp0dtceavIwxppRa6ZRX1bdVtaeqDgD2ABvKKXoNZZq7VHWn+54KfIHTF1NzotsD0DVoN9v2ZJOVZ/N6GWMM1N4or0bueytgJH76SEQkCjgP+LLUvnARqVe8DQzFaUKrOcERENmC1uwAYP1uy1KMMQZqb4Gtz0QkGmfN+ntVda+I3AWgqq+7Za4AvlPVg6XOawx8ISLg1P1DVZ1eg/V2xHQg+uBWANamZNKzVYMar4IxxtQ1tRJQVLW/n32vl/k8HhhfZt9mnKHGtSvmNIKSPyQiOJDVKftruzbGGFMn2JPyxyOmA5KfyfnNfSzcsqfy8sYYcwqwgHI83JFeQ2L3s353FqmZubVcIWOMqX0WUI5HzGkA9Ap3nm+ZtymjNmtjjDF1ggWU41GvKQRF0LRwO/VCPBZQjDEGCyjHRwRiOhCQvoGz20YzZ1N6bdfIGGNqnQWU4xVzGqRv4Jx20Wzfk8P2PTbzsDHm1GYB5XjFdIADyZzbOhSwfhRjjLGAcrzcjvn2ASnERARZs5cx5pRnAeV4uQFF0jfSt10MczdloKq1XCljjKk9FlCOV8O2IAGQvo5+7aJJy8xjdYqtj2KMOXVZQDlenmCIOR2SE7jwjCaEeAMYPyeptmtljDG1xgLKiWh/AWydQwNvAVfHt2TKsh2kHrCn5o0xpyYLKCei/QVQlA9Jcxh7bhuKfMq7c5Nqu1bGGFMrLKCciFbngCcUNn5P6+hwLurShInzt9qiW8aYU5IFlBPhDYE2/WHjTABu79+WA7mFfLRoey1XzBhjap4FlBPVfjDs2QwZm+jRqgG94xryzq9bKPLZEGJjzKnFAsqJaj/Yed/0IwC3nhvHjn05fL9mdy1Wyhhjal5trSn/oIisFJFVIvKQn+MDRWS/iCxzX38udewiEVknIhtF5PGarbkfDdtCgzjY+D0Agzs1pnn9UBtCbIw55dR4QBGRLsDtQG+c5XyHiUgHP0V/UdXu7utp99xA4FXgYqAzMEZEOtdQ1f0TcbKULT/D/h14AgO4oW9r5m3OYO0ue9DRGHPqqI0MpRMwX1WzVbUQmA1ccZTn9gY2qupmVc0HJgPDq6meR6/zCCjIgRc7w2v9uFG+JcQrJVlKYZHPRn4ZY056nlq450rgGRGJBnKAS4AEP+X6ishyYCfwiKquApoDpYdQJQN9/N1ERO4A7gBo1apV1dXenzb94Z55sH4GrP2GsB+fYFL0UG5YegOBAcL0lbsoUmXu44MIC6qNH7kxxlS/Gs9QVHUN8A9gJjAdWA6U/fN9CdBaVc8EXgGmuPvF3yXLuc84VY1X1fjY2NgqqXuFGnWCcx+Csd/B+U/QY993jA/4Gz8sWUP7RhHsyy5gzkab4t4Yc/KqlU55VX1bVXuq6gBgD7ChzPEDqprlbn8LeEUkBicjaVmqaAucDKbuEIHzHoVR79LTu5U5ce/y/s09qI6Q520AACAASURBVBfs4YdyRn5l5haw92B+DVfUGGOqVm2N8mrkvrcCRgKTyhxvIiLibvfGqWcGsAjoICJtRCQIuAb4qibrftS6jCRgxP8I3D6XoOmPMOC0GH5Ym4rPz/Mp90xcwvVvLzhs3y8b0rjl3YUWaIwxvxm19RzKZyKyGvgauFdV94rIXSJyl3t8FLDS7UN5GbhGHYXAfcAMYA3wsdu3Ujd1HQUDHoWl73Nn8HTSMvNI3LH/sCLbMrL5ZUM6q3YeIGV/Tsn+d+ck8dO6NO58fzF5hUU1XXNjjDlmtdXk1V9VO6vqmar6g7vvdVV93d3+r6qe4R4/W1Xnljr3W1U9TVXbqeoztVH/YzLwj9BxGF1X/4fGsveIZq9PFx8aY/DLBmfVx9yCIuZuSqdjk3osTNrDHz5bYYt3GWPqPHtSvroFBMDgvyK+Qh6ITuD7Naklh4p8yqeLkxlwWiyN6gXz8/o0ABZu2UNugY/HLurI74acxudLdzChzCzGH8zfyn9mrq/Jb2KMMRWygFITYtpD63MZVjSTtSn72LEvBwrzWT37U3buz2F0fEv6d4jl143pFPmUn9alEuQJ4Oy20dw3qD3dWkTx5fLDxx68/esWxv28ifxC31FXY+6mdL5fbVPCGGOqhwWUmtLzRqJykjk7YA2TF27DN/PPdJ19G5eGrmJw50YMOC2GfdkFrNyxn9nr0nik0WJC3x6AFOXTr30MK5L3k53vjK5OPZDLlvSD5Bb4WLZ931Hdfubq3dz49kLum7SEjKy86vymxphTlAWUmtL5cgiJ4t7IOSyd9QUBC14D4NboVQR7AunXPgaAiQu2sjk9i6tzP4HdK2HDTPq0aUihT1m8dS8A87fsKbnsvE2VP9sye30a905cQrvYCPIKfUyYt7UavqAx5lRnAaWmeEOh22j6Fczlrci32eFpxY/aizMPzgVfETERwXRpHskni50spn52knNe4kfExzUkMEBYsNkJJAs2ZxAR7KFT00jmbU6v8LYbdmdyx3sJtGsUwUd3ns2QTo15b15SSbZjjDFVxQJKTep5E1KUT0j+Hprf+j6DRt2DJycNkp2ZZ/p3iEUVbg+dDSH1oedNsH4GEXqQLs0iWbDFyUYWbNlDfFwDzm0fzZJt+8gtKH9Y8XtuNjLh1rOoHxbEnee1Y192AZMX2iJgxpiqZQGlJjXpAn3uhstehmbdocMQCPDC2q8BGNAhlmj2M9A3D84c4wSUojxY/RV92kazfPt+kvdmszE1iz5tounbLpr8Qh9L3KawsnLyi5iybAeXdG1Ko3ohAPRq7SwC9vavWygoOvoOfWOMqYwFlJp28fPQ4zpnOyQK2gyANVNBlfi4BjzXdgWBWgjxt0Dzns56K4kf0adNQ87RxeS9cxmN2Euftg05y20Km7fZfz/KNytSyMwtZPRZLQ/bf+d5bdmxL4fpK3dV97c1xpxCLKDUto6Xwt4tkLoGb94+huZ8C637Qezpzrxg3UZD0q/02/Yab3tfoF1mAjcH/0jX5lHUC/HSpXkUSzbuAD8PPn60aBttY8Lp06bhYfvPP70RDcOD+Glt6hHnlKfIp7w+exPJe7NP+CsbY05OFlBqW8dLnfdvH4H/6w77tsE5Dxw63vUqQAmZ9yLzg/oyp+gMrvHMxovTXHVps4O8ufsaiiaMgH2H+kU2pmayKGkvo89qiTstWomAAKFvu2jmbEo/7An8xz9L5N05W/xW87MlyTw/bS1v/+r/uDHGWECpbfWaQMs+sHUOtO4Ld8+F0y86dDy6HZx9Dwx6gh+6/ov3iobSsCi9ZMnhEXvfRVBIXgj/6wtL3gNg8sLteAKEkT1b+L1tv3Yx7D6Qx6a0gwBs35PN5EXbeW7aWrbvOTwLyc4v5IUZ6wD4YU2qTQNTB6kqnyRsdx6aNaaWWECpC0a+Cbf/CNd+5KyrUtZFz8GAR+l/eiN+8PWgIDQWFo+HnUtptO1bxnMZ/2jzLjTvAV/dT8Gc//LZkmSGdG5MbL1gv7c8133uZc5GZ9jxtJUpJceen772sLLjft5MamYeI3s0Z9uebDalZVXN9y5l2fZ9zLSn+I/btJW7ePTTRN6bl1TbVTGnMAsodUGD1tC8V6XFBp4Wy8xHBuPtdT1smAFTH4awaHZ3uYP31ioHrvoYOl2Od+afGJw3kxvObn34Bea+4jSrvdSNVh8OYHjkhpKA8k1iCl2bR3HPwHZ8k5jCQvfhyd0Hcnlj9mYu7dqURy48HXCylKNxMK+QRz5ZflRP8z8xZQUPTFp62FLJmbkFzC9nwEFdp6oU+VmqoDocyC3gqa+cSbe3uBmnMbXBAspviIjQJiYcet4I6oOdS6D/I1zZtxO5BT6+XL4bHfkmS7w9eN77Fn0LFx462edzAkqAB1r1hcI8nmQcCZt3szXjIMuT93NJ16bcOaAdTaNCeHLKSv70xQpGvT6XIp/y2EUdaVY/lE5NI/mhTGd+fqGPV3/ayLn/+LEkQAH89etVfLo4mT98vsLvOjDFtmVks3LHAXIKivgm8dCcZc9PW8s14+azdJv/YdF12XPT1jLyf3Nq5F7/nrGOtKw82saEsyXdAoqpPRZQfosatoV2F0D91nDWWLq2iKJL80gmLtjGkp05XJd5P5kRbZBZzx46J3kRZO2GgY/DyDdg2IvE5O/gioJv+afbP3Jp16aEBgXyh0s6sW53Jl8u20m72AheHtODVtFhAAzu1IjFW/eyL9tZ+Gvptr1c9sqv/GvGOjJzC7njvQSWb9/HtytS+DhhO7c12ciOlJ18tbz8hTW/WeE0tzWODObjhGQA0jLz+GSxs/3v7357syr/uiGd5cn7Sc3Mrdb7LNu+j/fmb+WmvnEMOaMxWzOyaywzMqYsCyi/VVeNh9t/Ao/TRzKmdyvW7srkiSkr8QRHENr3dti1wnmB8/BkgNd5mBKgw2Dy487nAc/nzElcT9fmUSVB4/Izm/HrY+ez7M9DGH9Lby7q0qTktoM6NiLMd5DE+TOZsTKF0W/MJzO3gLdujOe7/zeABuFB3PzuQv7wWSL/V/8Tntj3Zz4K/zcvz0gsd6Gwb1ekcGaLKG7t14bFW/eyKS2L9+YlUVDk4/qzW/HrxnTmbqx4ipmqtjkti0EvzGJzOf1FRT5l137/wSK/0MeG1EwAFidVb3Y1YW4S9UO9/G7oabSNCSe/yMeOvdYxb2pHbS0B/KCIrBSRVSLykJ/j14lIovuaKyJnljqWJCIrRGSZiCTUbM3rkJBICI8u+Xj5mc0ICwpkTcoBruzVguAeo50AsmyS84zKmqnQ9jznYUpX0MXPEiG5POj5nEu6Nj3s8i0ahOEJPPKfx5kBSUwL+SMDfr4W+fh6+jUu5NsH+zO4c2MaR4bwwdg+eET5vb7N8Nwp0GEoHYvW88jB//Dh/KQjrrctI5sVO5zmtpFd6nObZxr13u5H8tyPGdKpMU9c2pmmUSH867t1NTq6bNLCbWxOP8iMVf4HCrz1y2YG/PMntmUc+VzO+t2ZFBQ5dV1USUBZvHUv5/3rJzamHt9Ah42pWXRtUZ96IV7axEQAsDm96gdNlCcnv2pXE124ZQ/vz0uq0muamlPjAUVEugC3A72BM4FhItKhTLEtwHmq2g34GzCuzPHzVbW7qsZXe4V/I+qFeBnevRkAN/RtDWEN4bQLYcXHsCvReXiy47DDT2rcmaUxl3OLZwa3rL8H1n4LW+fC7H/BF3fBjsWHyvqKYOGbBLw7lAiP8lrhZQwMSOSdg/dQf8YD8PWD8PVDxH03lrlRf+I6meE8T3PtxzD071wSuJDAH57iYN7hk1JOW5lCI/ZyTdYEYt/syROe9wnL2cUj+i539WtOiDeQBy7owNJt+3j000Rum7CIYa/8wn9mrj9syeRiqlphf83RKCzyMWWZ00Q3d9ORmZGqMmnhNvKLfLzj57md1TsPANAsKoSErXuOOF4sPSuPeycuYWtGtt/7VEZV2ZSWRbvYcACnfw2Orh8lPxs2zITvn4LUNcd8b3CCapenZnDfh0tITD66ZRQqrFKhj4c/XsbTU1cf0zo/pu7w1MI9OwHzVTUbQERmA1cA/ywuUHrJX2A+4P9hCnOYxy/qxOVnNqddrPOXKt2vg7VT4ZvfAXLoIcpS2lz/MhtndaL9lg9g8hh3r0BQOCR+BH3ugqbd4Zd/Q/o6aHcB+we+RN66XLTLk8j3f4KkOc6cY74iqNcEb0w76HMH9L4dRJC+95K2bS03rn2fqVM/ZNiVNzq3ydnL6XMfZm7IL3gW+eD0S5jf/EZemr6CyUF/p3nKR9DuIUb1asG7c7YwZekO2sVGEBXq5ZUfN/DqTxvp0iySEG8g3sAA0rPySN6bQ3hwIO+P7cNpjesBsGt/Lm/8vInrz2596GdTgV83ppOWmUdcdBiLkvaQX+gjyHPob6+ErXtJysimUb1gPk7YzkODO1A/LKjk+Kqd+wkPCmREj+a88fNmDuYVEh58+P9qRT7lwclL2ZudX5JZHqtdB3LJzi+irfudYiKCqBfiYXNFI73ysuD7v8CS953/ZuBMTnrz1GO69+qdB3hh+iqGRO9l9rpApiamcOd5bfnDxX6GvR+ljxZtI9ltrtuYmkXnZpFHlEnNzMUTEEDD8KAjjpW2+0AunyRs5+6B7QkMkArL1piiAmdQjNSR+lSD2ggoK4FnRCQayAEuASpquhoLTCv1WYHvRESBN1S1bPYCgIjcAdwB0KpVq6qod50XFealb7tDzWB0GAJhMU6HfMuzIaLREedE148iesTjUPQ7WD/D+cfeqi8EBML3f4X5/3MKNuoMo96FziNoHRDAQ8XTg13/aeUVEyF21L/Z8fxseq34KweHXEZ4eD2yJ17PObnzWNVyNGeOfBQatqVXkY8mOxuzL2su9X/5D/S8EW9YQ755oD+qlPxi374nm0kLt7Fix37yC30czC+kRYMwzm4bzTcrUrh1/CKm3NsPnyrXvjmfzekH+XjRdp4d2ZVLujblp7WpfLV8J3sO5lPoUxpHhvD3EV2ICvXy+ZId1A/z8siFp3Pfh0tZtn0fvUtNX/NpQjJhQYG8dn0vrnxtLhMXbOPe89uXHF+18wCdmkbSp200/5u1iWXb95Wsd1Pspe/XM2djBv+8shtTlu0oyWqKfZOYwqqd+0nPyiPEG8ifh3U+oglyU6oTOIozFBGpcKSXb+t8fJ/fSeD+raR1GE2D+KvwpibCD3+FrfOcB2uPQm5BEf/vo2X8IfhTbsz8kuzbfuaR2QWMn5PE3ee1Oyy4Hq2c/CJe/nEjLRuGsn1PDmtSDhwRUFSV699aQMPwICbfUXFd/zl9HZ8tSaZX64b0DU4CTxA06VpyfHNaFmtSMrm0W9Nyr1HWlvSDbEnPYlDHxsfy1RwFOfBKL+hyJQz927Gf/xtR4wFFVdeIyD+AmUAWsBzwuziHiJyPE1DOLbW7n6ruFJFGwEwRWauqP/u5zzjcprL4+PhTc9hLoNeZumXBa9BpWOVly5YZ9h/oeQMczIB2gyDgBFpIPcFkXvgip00dxeqPHqNDkyjCkn/lSbmbe676C0SFAuANDOCla3rA7mfg9X7w8wtw0bN4y/wybdkwjN9f1PHI+2xbwIP7JvDMxlbcP95HRG4K92d+wqX1lvF+yBgenFzIn79cxf6cAmIigmkdHUZggDB9ZQqpB3J59bqezFi1i6vjW9K/fSwiTrNXcUDJzi9kauJOLu3alF6tG9C/QwwT5iZxe/+2BHkC8PmUNSkHGNWrBT1b1SdAnH6B0gFlyba9vPrTRkb1asHVZ7Vk3e5MJi7YSpFPCQwQUg/kcu+HSwgMEKJCvew5mE/fttFcXKafq7ivpH2prKtNTPiR/TaZu8mc/lfCVk0ixRfN7wqeYOGKToSvK2Rg27N4wduAou+fJ+yWKQSU+mt+78F8nv12DY9edHrJbNUA/5m5noOpm7gh9BsEJXzVJO4b9DjTVu7isyU7GHtum2P4h+GYMC+JtMw8Jt1+NreMX8jqlANcWabM8uT9rN+dhYizammjyBB/l2L7nmymLNsBwNzVW+i7epSzHMT9S0r+Db/0/Qa+Wr6T9KwzuOmcOMDJGjMO5jnf9Zvfwa6V0O1q6DKSzVlernp9HhkH83njhl5ceEYTv/cuV+JHcGAHzPuvc81Swa0sVaWgSA/Lin8raqXGqvq2qvZU1QHAHmBD2TIi0g14Cxiuqhmlzt3pvqcCX+D0xZjy9L7dmWyyy6jjO79ZD+gw+MSCiavjWYP5rt4Iuuz4iODF43in6BIuvuERmrrB5DCNOztNdgvHQfrGo7tB5m746HoabJnKCwH/5d20a3gz6z4u9ywkKLYtYzNfZ3rLD7i+ZQY/d5nGouC7+Ewf4eOWnzO5z1aits7g2Zf/S0jhAUb2bE5UmJcuzaKYW2pVzGkrdnEwv4ir4p0U7bb+bUnNzHOGRaetJ+eDa2lQkMIZzZzJOzs2iTysHyW3oIhHP1lOk8gQ/nJZZwA6N40kt8BH0s7dsG97yYqcn999Dose7Mot9Rbw6+zvoODwUWWbUrOICPYcNhtC29gIduzLOdRZvvQDeKUnYasn817RhcwZMoUHbr2ZcTf0YniP5izbVcAr2UOJ2D6L259/k9SMvbBgHGyYyWuzN/HJ4mRmrUsruX5OfhFv/7qF/8Z+RUCAB1qfC8sncUajELq3rM+HC7Ye9eCJn9al8tevV/H7T5fzv582MvD0WPq2i+b0JpFHZGwAny9JJjBAUIUZq8qfKfvNXzYTIHB643pEr3oXcvY6fYhbZpeUWbZ9HwECT329im8SU0hM3scV/5vDOc/9yPZNq2HR25C2Fr55GH2hI2+Oe7nkv9UjHy8/tud9VGH+axDbCUIbwDeP+J3Mtdjfv1lDj6e/4905W35zQ8Bro8kLEWmkqqki0goYCfQtc7wV8Dlwg6quL7U/HAhQ1Ux3eyjwdA1W/bcnuh3c8m1t16JEo+F/Z+P7C9iqjal/+XOc0y6m/MKDnoTVX8K3v4Mbphze9pyxyZnPTAKctWO8ofDZWMjLhLt+hdz97P7lQ7yRjWk2+F7nL9Rf/03HH5+hI9MgMAhOvxhy98PSD+hVkM24ICAf5of3onvLqwE4p100785JIie/iNCgQD5N2EpcdBhnxTUAYECHGDo2qccHPy7hyqAnCd+bxB896bRqNhKAvq3C6LHsSYpm9iGw91henJvJ7rQ0Jl/oo97BbRDSjk5NIxF81P98DOxdToOYq2gUfDFd9nxH4Ie/5y8FeyEd9LmHkXYXwHmPQYtebEo7SLvY8MMm/yzumE/KOEinaA9Mewxfo05clXIj0R0682b/LiVlh7p/Ze/YdQb5b0/jd3mvEvTaP6AwHQ3wsq7gMaDzYSPQNqZmcaauo/uBH516tOwDH4yEtVO5tk9vfv9pIgu37KFP22hUlfwiH8GewCP+085en8ZtExIICYTOIRlcFnmAmy90+vA6N63HtJW7UNWS75Zf6OOr5Tu5uEsT1u7K5NsVu7ihb9yhC/qKICCQ1MxcJi/azsgeLTi9gY8rfv6cvLjzCU5LhIR3oN357DmYz7Y92Tw0uAO/bkjn6Y9mkeELp354KIU+Zc+sV2kZEAj3zCNnXwpJ4+/kz/kvctsVnxESF8+wl3/hrvcX88W95xAWVOpXqLtQHi3KjBXa9AOkrSWx9z9oFeWl/syHYflk6D6GsjbszmT83CQahgfx169X8/mSHfzfNd1L+skqk5lbwJNTVnLe6bFc0aPmu55rJaAAn7l9KAXAvaq6V0TuAlDV14E/A9HA/9x/UIXuiK7GwBfuPg/woapOr40vYI5Pzw4teL73xzRtEMFNZ8VVXLheYxj0BEz7Paz6ArqMdILItMcgo1TWMus5Z+qapF9gxGvQ+AwAWrc+5/DrDXjUydbS1kHn4c5IOIDCfNibBIW5bJj+Kn22foQc2AFRLejbLpo3ft7M4q172bohkRd33srmdjfitMY6/RYPD4qj/qej8Hl2sr7hYC7Z8z0FBWuBPlyX9S5tZQ6+OfPwzXmJEb4W/D5kB4GziyChEdwxi/aNmnKz93ui9yyBNgPov2UyswO+IvCLbGgez/7+f+aJD35kdNPdnJs8A94aBG3PZ1hKBA0aNIT12XDaUODwkV6d0udAfhZL2z/Ako2BjOvl/xdM8yaNod+9dJ71HAvzTydyyD9pMOfv/Lfo39we8SwbdseWlF2/6wBPeD+gMKwxnnMeAG8YRLWCJe9x2TUj+NvU1Xy4cBtBngD++MVK9mfnM+Xefoc1T63fnckDExP4b8R4LtJfkIJs5zfBjz/C1e/RuWkkkxZuJ2V/Ls3qO9nrT+tS2ZddwJU9W5Q0GWZk5RFdlA5T7nL++90ynXfmZlJY5OOuge2ImP9voiSb71rew9Dmv8C8VyFzF8t3BBBCHpcV/cB93i/xeOexqsEFtLxjMje/MYv2yV9A58shshlfryviH9kP82v0M7T7/jYYM5lPuy8jI+Ezpky4kmtv/73zpQ5mwPsjoTAHve4TEgK6kZNfRMPwIKJnvEiQNODKn5vSomEEM5v2wjPzSaePM/zwP6ie/XYNYd5Apj/Yn7mbMnhiykqemLKSD28/u+L/V3xF7MvM5Kb3V7I8eT9TE1NoEhl6eJ9qDaitJq/+qtpZVc9U1R/cfa+7wQRVvU1VG7hDg0uGB6vqZvecM1X1DFV9pjbqb07M48O6clO/o2xnjx8LTbrBjD/CzD/DB1c6I2UueQEeWAZjZ0KznrDhO+hxA3S/tuLrtT7HWbwsrNQaMZ4giD0Nmnajw4g/OLM3L5sEwFlxDfEECM98sZD4+ffTRPbSd8t/Dw2pLipkyPqn6B2wjqcC7uM5773skfp4f3wKNs+i7ab3GV84lP65L/JG4TCKQhpQeM6DMOodp6N28hiC9m7k0cCPWBHSi/SRnzAi72nS6neDIU/D2O+I6nge3q5XcOfuEWTetRgGP4Vvz2aGFc7kwvQJ8OFVsOgtoMzQ4RWfQGRz3tzWhJiIIM7veOSgjBIDHiX3tl95OOw57l4QzVVZD+PzhvMaz5Kx+9CyCAFrp9AzYCNywRMQHOE0hfa4HjbPIjRtGeMafcYTa4azeNw9ZGftZ292Af8ZPwnfxNGw4A127s3m1vGLeDzwfS7On4F0HgHDX4Whz8CmH+G9EXSNdoYMl272+nxJMjERQQzY+Ta37/wLtwZ8w8YZ/4PXzoHkxZC9h4L3R/H5vNVc3LUpbUJziVnxJrOkD1N2R0Ovm0GLYOn7bNqwhilBf6bdvMfxZKdC5+GcsfcHIpe9yT0NFxOuB9nf7RYAPl2cTFRsM0Ju+tRpcnzzfNoteYZu3mSGJ7/Aj/MWORWc9RzkZ0FUSwonjuHpNyZy4zsLefi/k2ia9ivfhgzjsUu7suNAPo/l3YrmHoCPb3JGfgH4fCT++jVz1+3gvkHtiY4I5rIzm3Hv+e2Yuymj/Pnw8rNh4ZsUunP07UlJ4qXR3WkdHcY9ExcfMXN4dZNTYSry+Ph4TUg4dZ+B/M3bvgjeHuxs97wJLv6H08RV2t6tENXCGZ12oiZc7vzF+8AyCAhg1P/mcHPK01wSuBAd9Q6B3/3Juf/YmfDlfbDuG5J6/J6B87oD8O82i7ky5d8QVA/qNeG7/h8TGBxOfFxDokK9h+6zbjpMuga8oeQVKlcH/oc7Lj+fez9cwuf3nEPPVg1Kii7bvo8Rr87h6eFncGPfOFbu2M+wV37ljWu6cOHqx2D9NLj0P3DWWM5+9geGxAXyt41Xkt3rTrrNOZdb+sXxp0s7V/rVv1+9m9veS8AbKPxyYwzRHw1jbsHpnPXED4QFKqnPn8lBXzBtnlhy6Ge9Pxle7AIoKgEs0Y70YjW++q3ZFd6JZjumky/BBGkeP2o8K7QtDwZ87CzLcNFzh26++iv4bCxFDdtxdvID3Dj4LO6/oAP7svM565nvearzbq7b8BAa2hDJcfulmnaHK99G9ybhm3gVc7Ur3foMJirxLcjL4sV2b/HOxnCWPjkEz8QrIHUN+7PzCPQVEDHmHedZLYCProd10ygIjWFdVihrLvua3m2jOe9fs3j0wtOdUXzbFsDmn6DzCAo8oRS+0odl/7+9O4+OqsgXOP79ZSchKxAIAYFI2B5KEGSVRXYFQXAZfDyRTQ6KGz4X0DMu4y7OPEZxBGcARcFh3HmyiaJyXFiVJcj6FAFZwo4QIAmp90dVoBO6s0An3XF+n3P65Hbd6u6qrk5X36q6v2sa0nDoZGq81Q1aDycr4y5y/96TeDlJWGx1oo5tJz80Ehm3Aalag3nr9jB29vf8qX4mQ/c+C21GQ4d7MB/diWxfyk5JIfnWaUSmdQTg+Ok8Oj6/hHZpSUy9tbWde1kzy67IPLKD/ANbCck9wRrTkHR2kluzBQljFvLzoVMMnLyUvjGbeOSeu89btl5aIrK6LOf7Vb5lBOrfT90r7a/Ym2dC/5fP70zARmz2R2cC9kjnyC/wy9dgDP+Tsoh+ocug+2OENh9oh9UOboOXW8LmeXDNROoPeJSODe3wwvFmg6FaQ8jNhoFT6ZWRRvemNQt3JmCve9PjccjN5vv0u1h7PJ75mXuIjgjlstT4Qlkz6iZweZ143vh2O/n55uwlBBqkJMHNb0J6b5h3P6ycRoPqMaTu/hTy81goncjLN2cXEZSkR7OajOjYgAd7N6ZW4zZsaTGeLqHrOPLFq7BqOsl5e1hQ+47C73V8HWh3BzS7HrnjO1o98R0Mm0dISBi1933JN7WH0fLk33gy91Y6yxrbmTS9Dno9XfjFm/WHIe8ReuQX3o16hl07twMwa/kOws+c5Ka9f4Zq6cj9G3ml5XxuyX2Mg4M/geoNef9YEx7JHUknWUv8ij9D/U5w++c0btGe307l8cPOI9BqOBzfx9H8SKakT7Xvv4i9Xf83SKxPePY+Pozox+KNVA6Q3QAADvBJREFUWbz//a+IwKArUm35LmlrY+ElNyE8qR7ZXR6nPesJefsG8iNiMF3GM37xAUaceYTQOi2JSr0Mrn6UkFGfIVXtsGHfy1N4qE9jHtvenA31h9pFJ5OvJHfnKiblDaJalRAiZ/aFD0bD8tep+uvXjGkdx6IN+/hpxw7b8X08Fvas5RBxvHOqPbfkPcGcy2eQ3fNFErJWwNKXaJC/k6XVn+eZE09wYNPXpWp7f9AjFKWKyj0JLzWGht1tiJvVb9hLMQ+cem5hwKd/tGPyA6fYZaDA+l1HGf7GCmbf3o5GYVn2l3tal+Jfyxg49BPfHorjP6etIDRE6HBpNd4a2fa8rB/98Cv3zVnDjGFX8sPOI0xespWNT/Wxk955p2HOrbB1EXNTx1F313xqReXQ9cSzNEmJ5+OxHS/ordi27ze2T76Oq8M3EBJRha9P1GVNlxnc3aNRyQ/Oy4Gc4+RFJvCXxVtoVjuOvtX2IpvmQecHvP8wANj+DafeHMQ+qhH7h6lcPfsoLyV8QM9j78PwBVCvAxt2H+W6V74mNiqcm1rV4V+rdtK4Vixzuh4jJLHu2Xm0oydzueKpxdzR5VIe6JnO/mXv0HNuKA8P6sAtbYqcn3ZgK6x9hyeO9mPOD1kkxUSQViPGa1sAkJ9P1qu9SD64kufyhvB9nf9i5fbD/LFfs2KXThtjGDZjJSt/ymJF49lw6hj9t99Ak2aX8+qNjZAlT8Oa2XD63JDfHpNETDjE5f8GPZ5ga9qtDHptGamJVZg5ss25Zd0fjLZDnRIKkbHk9HyWiJaDL/hkyrIeoWiHopQ38/777LwEV42Dbo8VXjptjF2O6jkXcxEOn8ih5VOLAXigVyPu6lY0GpFd6dTpxSWkJ8cSHx1O5q9H+erBq89lyMuBd4fZoyZgkrmF/RljGdPlUuomRV9QuXLP5HPVY3NYEj2B6Nwj9D39DPcMGUSf5qU/IfBCvPfhu/ReczexcpJsE0kVyUFaj7DnRjmrfznM9G9+ZmHmXsJChAX3dvK6GmrIP5axee9xPr+/C19uyeLef65hwb2daJpy/pn4YFeg3TbdXvrhr4MzGJCR6rugx3ZzaNnb/D2nN3N+yKJRzarMGtWuxLPzs46dovekpaQmViHvjOHA8Rw+Hdf5XAQAY2x08P2bYG8m61Z+xZGDe1nTcCyXtenG43M3kJ1zho/v6khqgkfHfPo3eGsgJDaww4kxxayiLIWydiiBWuWlVHC7cpQdp+78gJ3QLUrEb50JQGJMBCnxUew5eoq2ad5X5kSEhTC0fX0mLtpMYnQ4LT3mWAC7uODmNznz7gjYuogxY8YTVaP+RZUrPDSE+Oq1eSnmOXrXOs6P39Ym3YW0KU9JTTvTafkk2oVsZGTd3VxZPRd6PFEoT6t6ibSql8ieoyc5cTrP59LaCdc0ZcCr3/D8wo1EhoVSJTyU9GTfy3DbpSVRNTIMAXo1K+EExrjaJPV6iIeBB661P85LE+olOS6K5wZdzpi37eKO6cNaFw4nI2IvDx5bC9K6cknGaN6at5H56/dw4seVRISFMGd0u8KdCUBkLIz6rMTXLy/aoSjlTXJTGJdZoS/ZNCWOw9k5XF4n3meeIW0v4ZUlWzmcnUuaW9FVSGg4oX+YCdmHCI3xz5LR9ORYvthdi4g6tYgI3U69CzzaKYumKXEcIZZV0VcxcXhXiAr3mdfribEemqfGM/KqBry+9CeqV43ksjrxXiNpF4gMC+W+HulEhIVQJaL083JljRnWp3kt7u/ZiNAQKTGcS0J0BBNvasGTA/6DzzZmUSsu6vwfFEFAOxSlgsTd3RoyIKO21xMBCyRER3DDFXWYtXwHl/r6lS1S6NIGF6thclUWZO5h/a9HSasRU+yXsb/UiotiQEZt+l6WQmwxnUlp3dcjnfnr97Dr8Mlzk+zFGNUp7aJfszTu6X7+0GZxoiPC6N+idjmV5uLpKi+lgkTLSxKLH693RndOo0mtWNr5GBrzt4bJVck3sPznQ2cjOJc3EeGvg1uePZv/YkVHhPH09c0RsUNaqnzoEYpSlUy9ajEsvK9zhb1eek17JHQm39CoZulCgASjro2TWT6he6HYZ8q/9AhFKVWsBtVjKJgeqIgJ+fKUHBdVKPaZ8i/tUJRSxYoMC6V+NbsAoKKGvFTlpB2KUqpEDZOrEhkWwiUVsMJLVV46h6KUKtGoTml0alQjeC6nq4KSdihKqRK1aZBU6DLISnmjQ15KKaX8QjsUpZRSfqEdilJKKb8ISIciIveKSKaIbBCR+7zsFxF5WUS2icg6EbnCY99tIrLV3W6r2JIrpZTypcIn5UWkOXA70AbIARaKyDxjzFaPbNcA6e7WFngNaCsiScDjQGvAAKtFZK4x5nBF1kEppdT5AnGE0hRYZozJNsbkAV8BA4vkGQDMNNYyIEFEUoDewGJjzCHXiSwG+lRk4ZVSSnkXiA4lE+gsItVEJBq4Fih6fdJUYKfH/V0uzVf6eURktIisEpFV+/fv91vhlVJKeVfhHYoxZiPwAvboYiGwFsgrks3b2VOmmHRvr/O6Maa1MaZ1jRo1LqLESimlSiMgJzYaY6YB0wBE5FnskYanXRQ+aqkD7HbpXYukf1nS661evfqAiPxShiJWBw6UIX+w0/oEv99bnbQ+wa209alXlicNyDXlRSTZGJMlIpcAnwLtPSfWRaQvcBd2OKwt8LIxpo2blF8NFKz6+h5oZYw55OfyrSrLdZSDndYn+P3e6qT1CW7lVZ9AhV55X0SqAbnAWGPMYREZA2CMmQLMx3Ym24BsYLjbd0hEngJWuuf5k787E6WUUhcmUENenbykTfHYNsBYH4+dDkwvv9IppZS6EHqmvHevB7oAfqb1CX6/tzppfYJbudQnIHMoSimlfn/0CEUppZRfaIeilFLKL7RDKUJE+ojIZheYcnygy+OLiNQVkS9EZKMLsnmvS08SkcUueOZiEUl06UEfcFNEQkXkBxH5xN1vICLLXbnmiEiES49097e5/fU9nmOCS98sIr0DU5OzZUkQkfdEZJNrp/aVvH3Guc9apoi8IyJRlamNRGS6iGSJSKZHmt/aQ0Raich695iXRaRcL2/poz4T3edtnYh8KCIJHvu8vu++vvN8tW2xjDF6czcgFPg/IA2IwJ7F3yzQ5fJR1hTgCrcdC2wBmgEvAuNd+njgBbd9LbAAG22gHbDcpScBP7m/iW47MUB1uh+YDXzi7v8LGOy2pwB3uO07gSluezAwx203c20WCTRwbRkawDZ6ExjltiOAhMraPtgQRz8DVTzaZlhlaiOgM/YctkyPNL+1B7ACaO8eswC4JgD16QWEue0XPOrj9X2nmO88X21bbJkq+oMZzDf3YVjkcX8CMCHQ5Spl2T8GegKbgRSXlgJsdttTgVs88m92+28BpnqkF8pXgeWvA3wOdAM+cf+UBzz+Oc62DbAIezIs2KXvB1z+Qu3lmS8A9YnDfgFLkfTK2j4FcfSS3Hv+CTZYa6VqI6B+kS9gv7SH27fJI71QvoqqT5F9A4FZbtvr+46P77zi/v+Ku+mQV2GlDj4ZTNxwQktgOVDTGLMHwP1NdtkuOuBmOZsEPATku/vVgCPGRqQuWq6zZXb7j7r8wVIXsL/49gMz3DDeP0QkhkraPsaYX4GXgB3AHux7vprK3Ubgv/ZIpXAIqUDXC2AE9kgJyl6f4v7/fNIOpbBSB58MFiJSFXgfuM8Yc6y4rF7SyhRws7yISD8gyxiz2jPZS1ZTwr6A18VDGHY44jVjTEvgBHZIxZegrpObWxiAHS6pDcRgr1tUVGVqo+KUtfxBVS8ReRQbdHdWQZKXbH6vj3YohfkKShmURCQc25nMMsZ84JL3ib12DO5vlksvLuBmoOvcEegvItuBf2KHvSZhr4NTEM3Bs1xny+z2xwOHCI66FNgF7DLGLHf338N2MJWxfQB6AD8bY/YbY3KBD4AOVO42Av+1xy63XTS9wrmFAv2AIcaNV1H2+hzAd9v6pB1KYSuBdLe6IQI7mTg3wGXyyq0gmQZsNMb8xWPXXKBg5clt2LmVgvShbvVKO+CoO8RfBPQSkUT3K7SXS6swxpgJxpg6xpj62Pd8iTFmCPAFcKOPuhTU8UaX37j0wW6FUQPsFT9XVFA1CjHG7AV2ikhjl9Qd+JFK2D7ODqCdiES7z15BfSptGzl+aQ+37zcRaefen6Eez1VhRKQP8DDQ3xiT7bHL1/vu9TvPtZWvtvWtoibDKssNu7pjC3blw6OBLk8x5bwKewi6Dljjbtdixz4/B7a6v0kuvwCvunqtB1p7PNcIbCDObcDwANerK+dWeaW5D/024F0g0qVHufvb3P40j8c/6uq4mXJeZVOKumQAq1wbfYRdFVRp2wd4EtiEvUjeW9gVQ5WmjYB3sPM/udhf5iP92R7YS5NnusdMpsiCjAqqzzbsnEjBd8KUkt53fHzn+Wrb4m4aekUppZRf6JCXUkopv9AORSmllF9oh6KUUsovtENRSinlF9qhKKWU8gvtUJTyExE5IyJrRGStiHwvIh1KyJ8gIneW4nm/FJHW/iupUuVDOxSl/OekMSbDGNMCG2DvuRLyJ2Cj8ir1u6AdilLlIw44DDbemoh87o5a1ovIAJfneeBSd1Qz0eV9yOVZKyLPezzfTSKyQkS2iEiniq2KUqUTVnIWpVQpVRGRNdizxFOwMckATgEDjTHHRKQ6sExE5mKDRTY3xmQAiMg1wPVAW2NMtogkeTx3mDGmjYhcCzyOja2lVFDRDkUp/znp0Tm0B2aKSHNsGI9nRaQzNjx/KlDTy+N7ADOMi8FkjDnksa8g+Odq7DUwlAo62qEoVQ6MMd+5o5Ea2FhJNYBWxphcF1U5ysvDBN8hwk+7v2fQ/1sVpHQORalyICJNsJdXPYgN3Z7lOpOrgXou22/YyzcX+BQYISLR7jk8h7yUCnr6S0cp/ymYQwF7tHGbMeaMiMwC/ldEVmEjwG4CMMYcFJFvRCQTWGCMeVBEMoBVIpIDzAceCUA9lLogGm1YKaWUX+iQl1JKKb/QDkUppZRfaIeilFLKL7RDUUop5RfaoSillPIL7VCUUkr5hXYoSiml/OL/Ac2hXIJ29gIUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(batch_list,subtrain_rmse_list,label='Subtrain')\n",
    "plt.plot(batch_list,valid_rmse_list,label='Valid')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Batch V.S. RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING RMSE: 9.271778347127466\n"
     ]
    }
   ],
   "source": [
    "test_accumulated_SSE = 0\n",
    "test_accumulated_N = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):            \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        outputs = best_net(inputs)        \n",
    "        cn_loss = mse(outputs, targets) * len(inputs)\n",
    "        test_accumulated_N += len(inputs)\n",
    "        test_accumulated_SSE += cn_loss\n",
    "\n",
    "rmse = math.sqrt(test_accumulated_SSE / test_accumulated_N)\n",
    "print(\"TESTING RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device:  cpu\n",
      "Z 0.1\n",
      "Best Step: 15600\n",
      "Early stop at: 20601\n",
      "TESTING RMSE: 9.030499384221116\n",
      "Running on device:  cpu\n",
      "Z 0.5\n",
      "Best Step: 9700\n",
      "Early stop at: 14701\n",
      "TESTING RMSE: 9.030550497348223\n",
      "Running on device:  cpu\n",
      "Z 0.9\n",
      "Best Step: 16600\n",
      "Early stop at: 21601\n",
      "TESTING RMSE: 9.02092725838504\n",
      "Running on device:  cpu\n",
      "Z 1.0\n",
      "Best Step: 12500\n",
      "Early stop at: 17501\n",
      "TESTING RMSE: 9.025626256459386\n"
     ]
    }
   ],
   "source": [
    "z_list=[0.1, 0.5, 0.9, 1.0]\n",
    "z_tune_outcome_list=[]\n",
    "z_tune_outcome_list.append([0.0,rmse])\n",
    "\n",
    "for i in range(len(z_list)):\n",
    "    \n",
    "    best_net=Q8Train(net,z_list[i],False)\n",
    "    \n",
    "    test_accumulated_SSE = 0\n",
    "    test_accumulated_N = 0\n",
    "\n",
    "    # testing\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            targets = targets.reshape((-1, 1))\n",
    "            outputs = best_net(inputs)        \n",
    "            cn_loss = mse(outputs, targets) * len(inputs)\n",
    "            test_accumulated_N += len(inputs)\n",
    "            test_accumulated_SSE += cn_loss\n",
    "\n",
    "    rmse = math.sqrt(test_accumulated_SSE / test_accumulated_N)\n",
    "    print(\"TESTING RMSE:\", rmse)\n",
    "    z_tune_outcome_list.append([z_list[i],rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Z</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.271778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>9.030499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9.030550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9</td>\n",
       "      <td>9.020927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.025626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Z      RMSE\n",
       "0  0.0  9.271778\n",
       "1  0.1  9.030499\n",
       "2  0.5  9.030550\n",
       "3  0.9  9.020927\n",
       "4  1.0  9.025626"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(z_tune_outcome_list)\n",
    "df=pd.DataFrame(z_tune_outcome_list,columns = ['Z','RMSE'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8解釋：  \n",
    "Training和Validation RMSE的圖如上輸出所示，當z=0的時候，可得RMSE約為9.272。  \n",
    "比較 z = 0.1, 0.5, 0.9, 1.0，每個z值的表現都比z=0的時候還要來得好。另外，由表可知當z=0.9時有最好的RMSE表現，z=0.5的時候RMSE表現最差。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
